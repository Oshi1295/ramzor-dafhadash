# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import plotly.express as px
from datetime import datetime
import logging
import unicodedata
import re
import io
import traceback
import numpy as np

# PDF Parsing libraries
import pymupdf as fitz # PyMuPDF, Hapoalim & Credit Report
import pdfplumber # Leumi & Discount

from openai import OpenAI
from openai import APIError # Specific import for API errors
# Import specific OpenAI error types for more granular handling
# from openai import AuthenticationError, PermissionDeniedError, RateLimitError, APIConnectionError, InternalServerError

# --- Logging Setup ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- OpenAI Client Setup ---
client = None # Initialize client to None
try:
    # Attempt to get API key from secrets
    api_key = st.secrets["OPENAI_API_KEY"]
    if api_key: # Check if key exists and is not empty
       client = OpenAI(api_key=api_key)
       logging.info("OpenAI client initialized successfully.")
    else:
       logging.warning("OPENAI_API_KEY found in secrets but is empty.")
       st.error("××¤×ª×— OpenAI ×œ× ×”×•×’×“×¨ ×›×”×œ×›×”. ×©×™×¨×•×ª ×”×¦'××˜ ××™× ×• ×–××™×Ÿ.")

except Exception as e:
    logging.error(f"Error loading OpenAI API key or initializing client: {e}", exc_info=True)
    st.error(f"×©×’×™××” ×‘×˜×¢×™× ×ª ××¤×ª×— OpenAI ××• ×‘×”×¤×¢×œ×ª ×©×™×¨×•×ª ×”×¦'××˜: {e}. ×”×¦'××˜×‘×•×˜ ×¢×©×•×™ ×œ× ×œ×¤×¢×•×œ ×›×¨××•×™.")
    # Client remains None


# --- Helper Functions (Keep existing ones, assumed correct) ---
def clean_number_general(text):
    """Cleans numeric strings, handling currency symbols, commas, and parentheses."""
    if text is None: return None
    text = str(text).strip()
    text = re.sub(r'[â‚ª,]', '', text)
    if text.startswith('(') and text.endswith(')'): text = '-' + text[1:-1]
    if text.endswith('-'): text = '-' + text[:-1]
    try:
        if text == "": return None # Handle empty string after cleaning
        return float(text)
    except ValueError:
        logging.debug(f"Could not convert '{text}' to float."); # Changed to debug to reduce log noise
        return None

def parse_date_general(date_str):
    """Parses date strings in multiple formats."""
    if date_str is None or pd.isna(date_str) or not isinstance(date_str, str): return None
    date_str = date_str.strip()
    if not date_str: return None
    try: return datetime.strptime(date_str, '%d/%m/%Y').date()
    except ValueError:
        try: return datetime.strptime(date_str, '%d/%m/%y').date()
        except ValueError:
            logging.debug(f"Could not parse date: {date_str}"); # Changed to debug
            return None

def normalize_text_general(text):
    """Normalizes Unicode text (removes potential hidden chars, ensures NFC)."""
    if text is None: return None
    text = str(text).replace('\r', ' ').replace('\n', ' ').replace('\u200b', '').strip()
    return unicodedata.normalize('NFC', text)

# --- PDF Parsers (HAPOALIM, LEUMI, DISCOUNT, CREDIT REPORT) ---
# Keep the parser functions as they were in the previous version.
# Added some debug logging within the parsers instead of info for lines that don't match patterns
# to reduce log noise unless debugging the parsers specifically.
# Ensured numeric columns are handled gracefully (fillna, errors='coerce') in parsers' output.

# --- HAPOALIM PARSER (Assume correct from previous version) ---
def extract_transactions_from_pdf_hapoalim(pdf_content_bytes, filename_for_logging="hapoalim_pdf"):
    """Extracts Date and Balance from Hapoalim PDF based on line patterns."""
    transactions = []
    try:
        doc = fitz.open(stream=pdf_content_bytes, filetype="pdf")
    except Exception as e:
        logging.error(f"Hapoalim: Failed to open/process PDF {filename_for_logging}: {e}", exc_info=True)
        return pd.DataFrame()

    date_pattern_end = re.compile(r"\s*(\d{1,2}/\d{1,2}/\d{4})\s*$")
    balance_pattern_start = re.compile(r"^\s*[â‚ª]?[+\-]?\s*([\d,]+\.\d{2})")

    logging.info(f"Starting Hapoalim PDF parsing for {filename_for_logging}")

    for page_num, page in enumerate(doc):
        try:
            lines = page.get_text("text", sort=True).splitlines()
            for line_num, line_text in enumerate(lines):
                original_line = line_text
                line_normalized = normalize_text_general(original_line)

                if not line_normalized or len(line_normalized) < 10: continue

                date_match = date_pattern_end.search(original_line)
                if date_match:
                    date_str = date_match.group(1)
                    parsed_date = parse_date_general(date_str)

                    if parsed_date:
                        balance_match = balance_pattern_start.search(original_line)
                        if balance_match:
                            balance_str = balance_match.group(1)
                            balance = clean_number_general(balance_str)

                            balance_start_index = balance_match.start()
                            if balance_start_index > 0:
                                char_before = original_line[balance_start_index - 1]
                                if char_before not in (' ', 'â‚ª', '-', '+'):
                                    logging.debug(f"Hapoalim: Skipping line {line_num+1} due to unexpected char before balance: '{original_line[:balance_start_index].strip()}' -> '{original_line}'")
                                    continue

                            if balance is not None:
                                lower_line = line_normalized.lower()
                                if "×™×ª×¨×” ×œ×¡×•×£ ×™×•×" in lower_line or "×¢×•×‘×¨ ×•×©×‘" in lower_line or "×ª× ×•×¢×•×ª ×‘×—×©×‘×•×Ÿ" in lower_line or "×¢××•×“" in lower_line or "×¡×š ×”×›×œ" in lower_line or "×”×•×“×¢×” ×–×• ×›×•×œ×œ×ª" in lower_line:
                                    logging.debug(f"Hapoalim: Skipping potential header/footer/summary line: {original_line.strip()}")
                                    continue

                                transactions.append({
                                    'Date': parsed_date,
                                    'Balance': balance,
                                })
                                logging.debug(f"Hapoalim: Found transaction - Date: {parsed_date}, Balance: {balance}, Line: {original_line.strip()}")
                            # else: logging.debug(f"Hapoalim: Found date but failed to clean balance: {balance_str} in line: {original_line.strip()}")
                        # else: logging.debug(f"Hapoalim: Found date but no balance pattern match in line: {original_line.strip()}")
                    # else: logging.debug(f"Hapoalim: Found date pattern but failed to parse date string: {date_str} in line: {original_line.strip()}")
        except Exception as e:
            logging.error(f"Hapoalim: Error processing line {line_num+1} on page {page_num+1}: {e}", exc_info=True)
            continue

    doc.close()

    if not transactions:
        logging.warning(f"Hapoalim: No transactions found in {filename_for_logging}")
        return pd.DataFrame()

    df = pd.DataFrame(transactions)
    df['Date'] = pd.to_datetime(df['Date'])
    df['Balance'] = pd.to_numeric(df['Balance'], errors='coerce') # Ensure numeric, handle errors
    df = df.dropna(subset=['Date', 'Balance']) # Remove rows where date or balance parsing failed

    df = df.sort_values(by='Date').groupby('Date')['Balance'].last().reset_index()
    df = df.sort_values(by='Date').reset_index(drop=True) # Final sort

    logging.info(f"Hapoalim: Successfully extracted {len(df)} unique balance points from {filename_for_logging}")
    return df[['Date', 'Balance']]


# --- LEUMI PARSER (Assume correct from previous version) ---
def clean_transaction_amount_leumi(text):
    """Cleans Leumi transaction amount, handles potential unicode zero-width space."""
    if text is None or pd.isna(text) or text == '': return None
    text = str(text).strip().replace('â‚ª', '').replace(',', '')
    text = text.lstrip('\u200b')
    if '.' not in text: return None # Requires a decimal point
    try:
        val = float(text)
        if abs(val) > 100_000_000:
             logging.debug(f"Leumi: Transaction amount seems excessively large: {val} from '{text}'. Skipping.")
             return None
        return val
    except ValueError:
        logging.debug(f"Leumi: Could not convert amount '{text}' to float.");
        return None

def clean_number_leumi(text):
     """Specific cleaner for Leumi numbers (balances often). Uses general cleaner."""
     return clean_number_general(text)


def parse_date_leumi(date_str):
    """Specific date parser for Leumi. Uses general parser."""
    return parse_date_general(date_str)

def normalize_text_leumi(text):
    """Normalizes Leumi text, including potential Hebrew reversal correction."""
    if text is None or pd.isna(text): return None
    text = str(text).replace('\r', ' ').replace('\n', ' ').replace('\u200b', '').strip()
    text = unicodedata.normalize('NFC', text)
    if any('\u0590' <= char <= '\u05EA' for char in text):
       words = text.split()
       reversed_text = ' '.join(words[::-1])
       return reversed_text
    return text

def parse_leumi_transaction_line_extracted_order_v2(line_text, previous_balance):
    """Attempts to parse a line assuming a specific column order from text extraction."""
    line = line_text.strip()
    if not line or len(line) < 15: return None
    pattern = re.compile(
        r"^([\-\u200b\d,\.]+)\s+" # 1: Balance
        r"(\d{1,3}(?:,\d{3})*\.\d{2})?\s*" # 2: Optional Amount
        r"(\S+)?\s*"             # 3: Optional single non-space char/code
        r"(.*?)\s+"              # 4: Description
        r"(\d{1,2}/\d{1,2}/\d{2,4})\s+" # 5: Value Date
        r"(\d{1,2}/\d{1,2}/\d{2,4})$"   # 6: Transaction Date
    )

    match = pattern.match(line)
    if not match: return None

    balance_str = match.group(1)
    amount_str = match.group(2)
    value_date_str = match.group(5)
    # transaction_date_str = match.group(6) # Not used for balance points

    parsed_date = parse_date_leumi(value_date_str)
    if not parsed_date: return None

    current_balance = clean_number_leumi(balance_str)
    if current_balance is None: return None

    amount = clean_transaction_amount_leumi(amount_str) # Can be None

    debit = None; credit = None
    if amount is not None and amount != 0 and previous_balance is not None:
        balance_diff = round(current_balance - previous_balance, 2)
        tolerance = 0.01
        if abs(balance_diff + amount) <= tolerance: debit = amount
        elif abs(balance_diff - amount) <= tolerance: credit = amount
        # else: logging.debug(f"Leumi: Balance change ({balance_diff}) does not match amount ({amount}) for line: {line}")

    return {'Date': parsed_date, 'Balance': current_balance, 'Debit': debit, 'Credit': credit}


def extract_leumi_transactions_line_by_line(pdf_content_bytes, filename_for_logging="leumi_pdf"):
    """Extracts Date and Balance from Leumi PDF by processing lines."""
    transactions_data = []
    try:
        with pdfplumber.open(io.BytesIO(pdf_content_bytes)) as pdf:
            previous_balance = None
            found_first_balance = False
            logging.info(f"Starting Leumi PDF parsing for {filename_for_logging}")

            for page_num, page in enumerate(pdf.pages):
                try:
                    text = page.extract_text(x_tolerance=2, y_tolerance=2, layout=True)
                    if not text: continue

                    lines = text.splitlines()
                    for line_num, line_text in enumerate(lines):
                        normalized_line = normalize_text_leumi(line_text.strip())
                        if not normalized_line or len(normalized_line) < 10: continue

                        if not found_first_balance:
                            initial_balance_match = re.search(r"(?:×™×ª×¨×”\s+×§×•×“××ª|×™×ª×¨×ª\s+×¡×’×™×¨×”\s+×§×•×“××ª|×™×ª×¨×”\s+× ×›×•×Ÿ\s+×œ×ª××¨×™×š)\s+([\-\u200b\d,\.]+)", normalized_line)
                            if initial_balance_match:
                                bal_str = initial_balance_match.group(1)
                                initial_bal = clean_number_leumi(bal_str)
                                if initial_bal is not None:
                                    previous_balance = initial_bal
                                    found_first_balance = True
                                    logging.debug(f"Leumi: Found initial balance on page {page_num+1}: {initial_bal} from line: {normalized_line.strip()}")
                                    continue

                            if previous_balance is None:
                                initial_entry = parse_leumi_transaction_line_extracted_order_v2(normalized_line, None)
                                if initial_entry and initial_entry['Balance'] is not None:
                                     previous_balance = initial_entry['Balance']
                                     found_first_balance = True
                                     logging.debug(f"Leumi: Treating first parsed entry balance as initial balance: {previous_balance} from line: {normalized_line.strip()}")
                                     # Don't continue here, let it potentially be added below

                        parsed_data = parse_leumi_transaction_line_extracted_order_v2(normalized_line, previous_balance)

                        if parsed_data:
                            current_balance = parsed_data['Balance']
                            parsed_date = parsed_data['Date']

                            if parsed_data['Debit'] is not None or parsed_data['Credit'] is not None or previous_balance is None:
                                if previous_balance is None: # This is the first valid balance line found
                                    previous_balance = current_balance

                                # Append only if different from the last entry or if it's the first entry
                                if not transactions_data or (transactions_data[-1]['Date'] != parsed_date or transactions_data[-1]['Balance'] != current_balance):
                                     transactions_data.append({'Date': parsed_date, 'Balance': current_balance})
                                     logging.debug(f"Leumi: Appended transaction balance - Date: {parsed_date}, Balance: {current_balance}, Line: {normalized_line.strip()}")

                                previous_balance = current_balance # Update previous balance for the next line
                            else:
                                # Line matched format but no transaction amount, update previous_balance if valid
                                if current_balance is not None:
                                     previous_balance = current_balance
                                logging.debug(f"Leumi: Matched line format but no transaction amount detected, only updating previous balance if valid: {normalized_line.strip()}")

                except Exception as e:
                     logging.error(f"Leumi: Error processing line {line_num+1} on page {page_num+1}: {e}", exc_info=True)
                     continue

    except Exception as e:
        logging.error(f"Leumi: FATAL ERROR processing PDF {filename_for_logging}: {e}", exc_info=True)
        return pd.DataFrame()

    if not transactions_data:
        logging.warning(f"Leumi: No transaction balances found in {filename_for_logging}")
        return pd.DataFrame()

    df = pd.DataFrame(transactions_data)
    df['Date'] = pd.to_datetime(df['Date'])
    df['Balance'] = pd.to_numeric(df['Balance'], errors='coerce') # Ensure numeric
    df = df.dropna(subset=['Date', 'Balance']) # Remove rows where date or balance parsing failed

    df = df.sort_values(by='Date').groupby('Date')['Balance'].last().reset_index()
    df = df.sort_values(by='Date').reset_index(drop=True) # Final sort

    logging.info(f"Leumi: Successfully extracted {len(df)} unique balance points from {filename_for_logging}")
    return df[['Date', 'Balance']]

# --- DISCOUNT PARSER (Assume correct from previous version) ---
def parse_discont_transaction_line(line_text):
    """Attempts to parse a line from Discount assuming specific date/balance placement."""
    line = line_text.strip()
    if not line or len(line) < 20: return None

    date_pattern = re.compile(r"(\d{1,2}/\d{1,2}/\d{2,4})\s+(\d{1,2}/\d{1,2}/\d{2,4})$")
    date_match = date_pattern.search(line)
    if not date_match: return None

    line_before_dates = line[:date_match.start()].strip()
    if not line_before_dates: return None

    balance_pattern_start = re.compile(r"^[â‚ª]?\s*([+\-]?[\d,]+\.\d{2})(?:\s+[â‚ª]?\s*[+\-]?[\d,]+\.\d{2})?") # Primary pattern
    balance_match = balance_pattern_start.search(line_before_dates)

    if not balance_match:
         # Fallback for more flexible search
         balance_pattern_flexible = re.compile(r"^(?:.*?)\s*[â‚ª]?\s*([+\-]?[\d,]+\.\d{2})(?:\s+[â‚ª]?\s*[+\-]?[\d,]+\.\d{2})?")
         balance_match = balance_pattern_flexible.search(line_before_dates)
         if not balance_match:
            # logging.debug(f"Discount: Found dates but no clear balance pattern at start of '{line_before_dates}' from line: {line.strip()}")
            return None

    balance_str = balance_match.group(1)
    balance = clean_number_general(balance_str)

    if balance is None:
        logging.debug(f"Discount: Found dates but failed to clean balance: {balance_str} in line: {line.strip()}")
        return None

    date_str = date_match.group(1) # Use the first date found
    parsed_date = parse_date_general(date_str)

    if not parsed_date:
        logging.debug(f"Discount: Failed to parse date '{date_str}' from line: {line.strip()}")
        return None

    lower_line = line.lower()
    if any(phrase in lower_line for phrase in ["×™×ª×¨×ª ×¡×’×™×¨×”", "×™×ª×¨×” × ×›×•×Ÿ", "×¡×š ×”×›×œ", "×¡×”×›", "×¢××•×“"]):
         logging.debug(f"Discount: Skipping likely closing balance/summary/footer line: {line.strip()}")
         return None
    if any(header_part in lower_line for header_part in ["×ª××¨×™×š ×¨×™×©×•×", "×ª××¨×™×š ×¢×¨×š", "×ª×™××•×¨", "××¡××›×ª×", "×¡×›×•×", "×™×ª×¨×”"]):
         logging.debug(f"Discount: Skipping likely header line: {line.strip()}")
         return None

    logging.debug(f"Discount: Parsed transaction - Date: {parsed_date}, Balance: {balance}, Line: {line.strip()}")
    return {'Date': parsed_date, 'Balance': balance}


def extract_and_parse_discont_pdf(pdf_content_bytes, filename_for_logging="discount_pdf"):
    """Extracts Date and Balance from Discount PDF by processing lines."""
    transactions = []
    try:
        with pdfplumber.open(io.BytesIO(pdf_content_bytes)) as pdf:
            logging.info(f"Starting Discount PDF parsing for {filename_for_logging}")
            for page_num, page in enumerate(pdf.pages):
                try:
                    text = page.extract_text(x_tolerance=2, y_tolerance=2, layout=True)
                    if text:
                        lines = text.splitlines()
                        for line_num, line_text in enumerate(lines):
                            normalized_line = normalize_text_general(line_text)
                            parsed = parse_discont_transaction_line(normalized_line)
                            if parsed:
                                # Avoid adding duplicate entries for the same date and balance
                                if not transactions or (transactions[-1]['Date'] != parsed['Date'] or transactions[-1]['Balance'] != parsed['Balance']):
                                     transactions.append(parsed)
                                # else: logging.debug(f"Discount: Skipping duplicate date/balance entry for line: {normalized_line.strip()}")
                            # else: logging.debug(f"Discount: Line did not match transaction pattern: {normalized_line.strip()}")

                except Exception as e:
                    logging.error(f"Discount: Error processing page {page_num+1}: {e}", exc_info=True)
                    continue

    except Exception as e:
        logging.error(f"Discount: FATAL ERROR processing PDF {filename_for_logging}: {e}", exc_info=True)
        return pd.DataFrame()

    if not transactions:
        logging.warning(f"Discount: No transaction balances found in {filename_for_logging}")
        return pd.DataFrame()

    df = pd.DataFrame(transactions)
    df['Date'] = pd.to_datetime(df['Date'])
    df['Balance'] = pd.to_numeric(df['Balance'], errors='coerce') # Ensure numeric
    df = df.dropna(subset=['Date', 'Balance']) # Remove rows with parsing errors

    df = df.sort_values(by='Date').groupby('Date')['Balance'].last().reset_index()
    df = df.sort_values(by='Date').reset_index(drop=True) # Final sort

    logging.info(f"Discount: Successfully extracted {len(df)} unique balance points from {filename_for_logging}")
    return df[['Date', 'Balance']]


# --- CREDIT REPORT PARSER (Assume correct from previous version) ---
COLUMN_HEADER_WORDS_CR = {
    "×©×", "××§×•×¨", "××™×“×¢", "××“×•×•×—", "××–×”×”", "×¢×¡×§×”", "××¡×¤×¨", "×¢×¡×§××•×ª",
    "×’×•×‘×”", "××¡×’×¨×ª", "××¡×’×¨×•×ª", "×¡×›×•×", "×”×œ×•×•××•×ª", "××§×•×¨×™", "×™×ª×¨×ª", "×—×•×‘",
    "×™×ª×¨×”", "×©×œ×", "×©×•×œ××”", "×‘××•×¢×“", "×¤×¨×˜×™", "×¢×¡×§×”", "×‘× ×§", "××•×¦×¨", # Added "×‘× ×§", "××•×¦×¨"
    "×¡×•×’", "××˜×‘×¢", "×× ×™×™×Ÿ", "×™××™×", "×¨×™×‘×™×ª", "×××•×¦×¢×ª" # Add more potential headers
}
BANK_KEYWORDS_CR = {"×‘× ×§", "×‘×¢\"×", "××’×•×“", "×“×™×¡×§×•× ×˜", "×œ××•××™", "×”×¤×•×¢×œ×™×", "××–×¨×—×™",
                 "×˜×¤×—×•×ª", "×”×‘×™× ×œ××•××™", "××¨×›× ×ª×™×œ", "××•×¦×¨", "×”×—×™×™×œ", "×™×¨×•×©×œ×™×",
                 "××™×’×•×“", "××™××•×Ÿ", "×™×©×™×¨", "×›×¨×˜×™×¡×™", "××©×¨××™", "××§×¡", "×¤×™× × ×¡×™×",
                 "×›××œ", "×™×©×¨××›×¨×˜", "×¤×•×¢×œ×™×", "×œ××•××™", "×“×™×¡×§×•× ×˜", "××–×¨×—×™", "×˜×¤×—×•×ª", "×‘×™× ×œ××•××™", "××¨×›× ×ª×™×œ", "××™×’×•×“"} # Added variations

def clean_credit_number(text):
    """Specific cleaner for credit report numbers, uses general."""
    return clean_number_general(text)

def process_entry_final_cr(entry_data, section, all_rows_list):
    """Processes a collected entry (bank name + numbers) into structured data."""
    if not entry_data or not entry_data.get('bank') or not entry_data.get('numbers'):
        logging.debug(f"CR: Skipping entry due to missing data: {entry_data}")
        return

    bank_name_raw = entry_data['bank']
    bank_name_cleaned = re.sub(r'\s*XX-[\w\d\-]+.*', '', bank_name_raw).strip()
    bank_name_cleaned = re.sub(r'\s+\d{1,3}(?:,\d{3})*$', '', bank_name_cleaned).strip()
    bank_name_cleaned = re.sub(r'\s+×‘×¢\"×$', '', bank_name_cleaned, flags=re.IGNORECASE).strip()
    bank_name_cleaned = re.sub(r'\s+×‘× ×§$', '', bank_name_cleaned, flags=re.IGNORECASE).strip()
    bank_name_final = bank_name_cleaned if bank_name_cleaned else bank_name_raw

    is_likely_bank = any(kw in bank_name_final for kw in ["×œ××•××™", "×”×¤×•×¢×œ×™×", "×“×™×¡×§×•× ×˜", "××–×¨×—×™", "×”×‘×™× ×œ××•××™", "××¨×›× ×ª×™×œ", "×™×¨×•×©×œ×™×", "××™×’×•×“", "×˜×¤×—×•×ª", "××•×¦×¨"]) # Specific bank names
    if is_likely_bank and not bank_name_final.lower().endswith("×‘×¢\"×"):
        bank_name_final += " ×‘×¢\"×"
    elif any(kw in bank_name_final for kw in ["××§×¡ ××™×˜ ×¤×™× × ×¡×™×", "××™××•×Ÿ ×™×©×™×¨"]) and not bank_name_final.lower().endswith("×‘×¢\"×"):
         bank_name_final += " ×‘×¢\"×"

    numbers_raw = entry_data['numbers']
    # Clean and filter out None values
    numbers = [clean_credit_number(n) for n in numbers_raw if clean_credit_number(n) is not None]

    num_count = len(numbers)
    limit_col, original_col, outstanding_col, unpaid_col = np.nan, np.nan, np.nan, np.nan

    if num_count >= 1: # Need at least one number
        val1 = numbers[0] if num_count > 0 else np.nan
        val2 = numbers[1] if num_count > 1 else np.nan
        val3 = numbers[2] if num_count > 2 else np.nan
        val4 = numbers[3] if num_count > 3 else np.nan

        if section in ["×¢×•\"×©", "××¡×’×¨×ª ××©×¨××™"]:
             # Expected: Limit, Outstanding, Unpaid (optional)
             # Could be 2 numbers (Limit, Outstanding) or 3 (Limit, Outstanding, Unpaid)
             if num_count >= 2:
                  limit_col = val1
                  outstanding_col = val2
                  unpaid_col = val3 if num_count > 2 else 0.0
             elif num_count == 1: # If only one number, what is it? Assume Outstanding might be listed alone sometimes? Less likely.
                  # This might indicate malformed entry or a section with only one number field.
                  # Assuming the most common case is at least Limit+Outstanding (2 numbers).
                  # Log and skip or try best guess? Let's skip if less than 2 for these sections for safety.
                  logging.debug(f"CR: Skipping ×¢×•\"×©/××¡×’×¨×ª entry for '{bank_name_final}' with only 1 number.")
                  return


        elif section in ["×”×œ×•×•××”", "××©×›× ×ª×”"]:
            # Expected: Num Payments (optional), Original, Outstanding, Unpaid (optional)
            # Could be 2 numbers (Original, Outstanding), 3 (Original, Outstanding, Unpaid OR Num Payments, Original, Outstanding), or 4.
            if num_count >= 2:
                 # Check if the first number looks like a payment count (small integer)
                 if pd.notna(val1) and val1 == int(val1) and val1 > 0 and val1 < 600 and num_count >= 3: # Heuristic: payments > 0 and < 600 (50 years)
                      # Assuming Num Payments, Original, Outstanding, Unpaid
                      original_col = val2 if num_count > 1 else np.nan
                      outstanding_col = val3 if num_count > 2 else np.nan
                      unpaid_col = val4 if num_count > 3 else 0.0
                 else:
                     # Assuming Original, Outstanding, Unpaid (if 3+ numbers) or Original, Outstanding (if 2 numbers)
                     original_col = val1
                     outstanding_col = val2 if num_count > 1 else np.nan
                     unpaid_col = val3 if num_count > 2 else 0.0
            elif num_count == 1:
                 # If only one number, assume it's the outstanding balance? Less common, but possible.
                 # Let's assume it's the outstanding balance if that's all we get.
                 outstanding_col = val1
                 original_col = np.nan # Original is unknown
                 unpaid_col = 0.0 # Assume 0 unpaid if not listed
                 logging.debug(f"CR: Processing ×”×œ×•×•××”/××©×›× ×ª×” entry for '{bank_name_final}' with only 1 number as Outstanding.")

        else: # Default case (e.g., "××—×¨" section) or fallback
            # Try to interpret the numbers based on quantity, assuming common loan-like structure
            if num_count >= 2:
                 original_col = val1
                 outstanding_col = val2
                 unpaid_col = val3 if num_count > 2 else 0.0
            elif num_count == 1:
                 outstanding_col = val1
                 original_col = np.nan
                 unpaid_col = 0.0
            # If num_count is 0, it was caught at the beginning of the function.
            # Limit is not applicable here (np.nan)
            logging.debug(f"CR: Processing '××—×¨' entry for '{bank_name_final}' with {num_count} numbers.")


        # Append the processed row if at least outstanding or limit is not NaN
        if pd.notna(outstanding_col) or pd.notna(limit_col):
             all_rows_list.append({
                 "×¡×•×’ ×¢×¡×§×”": section,
                 "×©× ×‘× ×§/××§×•×¨": bank_name_final,
                 "×’×•×‘×” ××¡×’×¨×ª": limit_col,
                 "×¡×›×•× ××§×•×¨×™": original_col,
                 "×™×ª×¨×ª ×—×•×‘": outstanding_col,
                 "×™×ª×¨×” ×©×œ× ×©×•×œ××”": unpaid_col
             })
             logging.debug(f"CR: Appended row: {all_rows_list[-1]}")
        else:
            logging.debug(f"CR: Skipping entry for '{bank_name_final}' as no outstanding or limit found after number parsing.")


def extract_credit_data_final_v13(pdf_content_bytes, filename_for_logging="credit_report_pdf"):
    """Extracts structured credit data from the report PDF."""
    extracted_rows = []
    try:
        with fitz.open(stream=pdf_content_bytes, filetype="pdf") as doc:
            current_section = None
            current_entry = None
            last_line_was_id = False
            potential_bank_continuation_candidate = False

            section_patterns = {
                "×—×©×‘×•×Ÿ ×¢×•×‘×¨ ×•×©×‘": "×¢×•\"×©",
                "×”×œ×•×•××”": "×”×œ×•×•××”",
                "××©×›× ×ª×”": "××©×›× ×ª×”",
                "××¡×’×¨×ª ××©×¨××™ ××ª×—×“×©×ª": "××¡×’×¨×ª ××©×¨××™",
                "××—×¨": "××—×¨" # Catch-all
            }
            number_line_pattern = re.compile(r"^\s*.*?(-?\d{1,3}(?:,\d{3})*\.?\d*)\s*.*?$") # Relaxed number pattern
            id_line_pattern = re.compile(r"^XX-[\w\d\-]+.*$")

            logging.info(f"Starting Credit Report PDF parsing for {filename_for_logging}")

            for page_num, page in enumerate(doc):
                try:
                    lines = page.get_text("text", sort=True).splitlines()
                    logging.debug(f"Page {page_num + 1} has {len(lines)} lines.")

                    for line_num, line_text in enumerate(lines):
                        line = normalize_text_general(line_text)
                        if not line: potential_bank_continuation_candidate = False; continue

                        is_section_header = False
                        for header_keyword, section_name in section_patterns.items():
                            if header_keyword in line and len(line) < len(header_keyword) + 25 and line.count(' ') < 6:
                                if current_entry and not current_entry.get('processed', False):
                                    process_entry_final_cr(current_entry, current_section, extracted_rows)
                                current_section = section_name
                                current_entry = None
                                last_line_was_id = False
                                potential_bank_continuation_candidate = False
                                is_section_header = True
                                logging.debug(f"CR: Detected section header: {line} -> {current_section}")
                                break
                        if is_section_header: continue

                        if line.startswith("×¡×”\"×›") or line.startswith("×”×•×“×¢×” ×–×• ×›×•×œ×œ×ª") or "×¢××•×“" in line:
                            if current_entry and not current_entry.get('processed', False):
                                process_entry_final_cr(current_entry, current_section, extracted_rows)
                            current_entry = None
                            last_line_was_id = False
                            potential_bank_continuation_candidate = False
                            logging.debug(f"CR: Detected summary/footer line: {line}")
                            continue

                        if current_section:
                            number_match = number_line_pattern.match(line)
                            if number_match:
                                if current_entry:
                                    try:
                                        number_str = number_match.group(1)
                                        number = clean_credit_number(number_str)
                                        if number is not None:
                                            num_list = current_entry.get('numbers', [])
                                            if last_line_was_id:
                                                if current_entry and not current_entry.get('processed', False):
                                                     process_entry_final_cr(current_entry, current_section, extracted_rows)
                                                current_entry = {'bank': current_entry['bank'], 'numbers': [number], 'processed': False}
                                                logging.debug(f"CR: Detected number after ID line, starting new entry for bank '{current_entry['bank']}' with first number: {number}")
                                            else:
                                                 if len(num_list) < 5:
                                                     current_entry['numbers'].append(number)
                                                     logging.debug(f"CR: Added number {number} to current entry for bank '{current_entry.get('bank', 'N/A')}'. Numbers: {current_entry['numbers']}")
                                                 else:
                                                     logging.debug(f"CR: Skipping extra number {number} for bank '{current_entry.get('bank', 'N/A')}'. Max numbers reached.")

                                    except Exception as e: # Catch potential errors during cleaning/appending
                                        logging.error(f"CR: Error processing number line '{line.strip()}': {e}", exc_info=True)

                                last_line_was_id = False
                                potential_bank_continuation_candidate = False
                                continue

                            is_id_line = id_line_pattern.match(line)
                            if is_id_line:
                                last_line_was_id = True
                                potential_bank_continuation_candidate = False
                                logging.debug(f"CR: Detected ID line: {line}")
                                continue

                            is_noise_line = any(word in line.split() for word in COLUMN_HEADER_WORDS_CR) or line in [':', '.', '-', 'â€”'] or (len(line.replace(' ','')) < 3 and not line.replace(' ','').isdigit()) or re.match(r"^\d{1,2}/\d{1,2}/\d{2,4}$", line) # Add date-only lines as noise
                            if is_noise_line:
                                last_line_was_id = False
                                potential_bank_continuation_candidate = False
                                logging.debug(f"CR: Skipping likely noise line: {line}")
                                continue

                            # If not a special line, treat as potential bank name or description
                            contains_number = any(char.isdigit() for char in line.replace(',', '').replace('.', '')) # Check for digits
                            contains_date_format = re.search(r"\d{1,2}/\d{1,2}/\d{2,4}", line)
                            is_non_bank_phrase = any(phrase in line for phrase in ["×¡×š ×”×›×œ", "×¡×”×›", "×¡×”×´×›", "×¨×™×›×•×– × ×ª×•× ×™×", "×”×•×“×¢×” ×–×• ×›×•×œ×œ×ª"]) # Add more phrases

                            if not contains_number and not contains_date_format and not is_non_bank_phrase:
                                 cleaned_line = re.sub(r'\s*XX-[\w\d\-]+.*|\s+\d+$', '', line).strip()
                                 common_continuations = ["×œ×™×©×¨××œ", "×‘×¢\"×", "×•××©×›× ×ª××•×ª", "× ×“×œ\"×Ÿ", "×“×™×¡×§×•× ×˜", "×”×¨××©×•×Ÿ", "×¤×™× × ×¡×™×", "××™×’×•×“", "××©×¨××™", "×—×‘×¨×”", "×œ××™××•×Ÿ", "×©×™×¨×•×ª×™×"]
                                 seems_like_continuation_text = any(cleaned_line.startswith(cont) for cont in common_continuations) or (len(cleaned_line) > 3 and ' ' in cleaned_line)

                                 if potential_bank_continuation_candidate and current_entry and seems_like_continuation_text:
                                     current_entry['bank'] = (current_entry['bank'] + " " + cleaned_line).replace(" ×‘×¢\"× ×‘×¢\"×", " ×‘×¢\"×").strip()
                                     logging.debug(f"CR: Appended continuation '{cleaned_line}' to bank name. New bank name: '{current_entry['bank']}'")
                                     potential_bank_continuation_candidate = True # Still potentially continuing
                                 elif len(cleaned_line) > 3 and any(kw in cleaned_line for kw in BANK_KEYWORDS_CR):
                                      if current_entry and not current_entry.get('processed', False):
                                           process_entry_final_cr(current_entry, current_section, extracted_rows)
                                      current_entry = {'bank': cleaned_line, 'numbers': [], 'processed': False}
                                      potential_bank_continuation_candidate = True
                                      logging.debug(f"CR: Started new entry with bank name: '{cleaned_line}'")
                                 else: # Neither continuation nor new bank start
                                      if current_entry and current_entry.get('numbers') and not current_entry.get('processed', False):
                                          process_entry_final_cr(current_entry, current_section, extracted_rows)
                                          current_entry['processed'] = True
                                      potential_bank_continuation_candidate = False

                                 last_line_was_id = False
                            else: # Contains numbers/dates or is a known non-bank phrase
                                  if current_entry and current_entry.get('numbers') and not current_entry.get('processed', False):
                                       process_entry_final_cr(current_entry, current_section, extracted_rows)
                                       current_entry['processed'] = True
                                  last_line_was_id = False
                                  potential_bank_continuation_candidate = False

                except Exception as e:
                    logging.error(f"CR: Error processing line {line_num+1} on page {page_num+1}: {e}", exc_info=True)
                    continue

            if current_entry and not current_entry.get('processed', False):
                process_entry_final_cr(current_entry, current_section, extracted_rows)

    except Exception as e:
        logging.error(f"CreditReport: FATAL ERROR processing {filename_for_logging}: {e}", exc_info=True)
        return pd.DataFrame()

    if not extracted_rows:
        logging.warning(f"CreditReport: No structured entries found in {filename_for_logging}")
        return pd.DataFrame()

    df = pd.DataFrame(extracted_rows)

    final_cols = ["×¡×•×’ ×¢×¡×§×”", "×©× ×‘× ×§/××§×•×¨", "×’×•×‘×” ××¡×’×¨×ª", "×¡×›×•× ××§×•×¨×™", "×™×ª×¨×ª ×—×•×‘", "×™×ª×¨×” ×©×œ× ×©×•×œ××”"]
    for col in final_cols:
        if col not in df.columns:
            df[col] = np.nan

    df = df[final_cols]

    for col in ["×’×•×‘×” ××¡×’×¨×ª", "×¡×›×•× ××§×•×¨×™", "×™×ª×¨×ª ×—×•×‘", "×™×ª×¨×” ×©×œ× ×©×•×œ××”"]:
        if col in df.columns:
             df[col] = pd.to_numeric(df[col], errors='coerce')
             if col == "×™×ª×¨×” ×©×œ× ×©×•×œ××”":
                  df[col] = df[col].fillna(0)

    df = df.dropna(subset=['×’×•×‘×” ××¡×’×¨×ª', '×¡×›×•× ××§×•×¨×™', '×™×ª×¨×ª ×—×•×‘', '×™×ª×¨×” ×©×œ× ×©×•×œ××”'], how='all').reset_index(drop=True)

    logging.info(f"CreditReport: Successfully extracted {len(df)} entries from {filename_for_logging}")

    return df


# --- Initialize Session State ---
if 'app_stage' not in st.session_state: st.session_state.app_stage = "welcome"
if 'questionnaire_stage' not in st.session_state: st.session_state.questionnaire_stage = 0
if 'answers' not in st.session_state: st.session_state.answers = {}
if 'classification_details' not in st.session_state: st.session_state.classification_details = {}
if 'chat_messages' not in st.session_state: st.session_state.chat_messages = []
if 'df_bank_uploaded' not in st.session_state: st.session_state.df_bank_uploaded = pd.DataFrame()
if 'df_credit_uploaded' not in st.session_state: st.session_state.df_credit_uploaded = pd.DataFrame()
if 'bank_type_selected' not in st.session_state: st.session_state.bank_type_selected = "×œ×œ× ×“×•×— ×‘× ×§"
if 'total_debt_from_credit_report' not in st.session_state: st.session_state.total_debt_from_credit_report = None
if 'uploaded_bank_file_name' not in st.session_state: st.session_state.uploaded_bank_file_name = None
if 'uploaded_credit_file_name' not in st.session_state: st.session_state.uploaded_credit_file_name = None


def reset_all_data():
    """Resets all session state variables to their initial state."""
    logging.info("Resetting all application data.")
    st.session_state.app_stage = "welcome"
    st.session_state.questionnaire_stage = 0
    st.session_state.answers = {}
    st.session_state.classification_details = {}
    st.session_state.chat_messages = []
    st.session_state.df_bank_uploaded = pd.DataFrame()
    st.session_state.df_credit_uploaded = pd.DataFrame()
    st.session_state.bank_type_selected = "×œ×œ× ×“×•×— ×‘× ×§"
    st.session_state.total_debt_from_credit_report = None
    st.session_state.uploaded_bank_file_name = None
    st.session_state.uploaded_credit_file_name = None


# --- Streamlit App Layout ---
st.set_page_config(layout="wide", page_title="×™×•×¢×¥ ×¤×™× × ×¡×™ ××©×•×œ×‘", page_icon="ğŸ§©")
st.title("ğŸ§© ×™×•×¢×¥ ×¤×™× × ×¡×™ ××©×•×œ×‘: ×©××œ×•×Ÿ ×•× ×™×ª×•×— ×“×•×—×•×ª")

# --- Sidebar ---
with st.sidebar:
    st.header("××¤×©×¨×•×™×•×ª")
    if st.button("×”×ª×—×œ ××—×“×© ××ª ×›×œ ×”×ª×”×œ×™×š", key="reset_sidebar_button"):
        reset_all_data()
        st.rerun()
    st.markdown("---")
    st.caption("Â© ×›×œ ×”×–×›×•×™×•×ª ×©××•×¨×•×ª. ×›×œ×™ ×–×” × ×•×¢×“ ×œ××˜×¨×•×ª ××‘×—×•×Ÿ ×¨××©×•× ×™ ×•××™× ×• ××”×•×•×” ×™×™×¢×•×¥ ×¤×™× × ×¡×™.")


# --- Main Application Flow ---

if st.session_state.app_stage == "welcome":
    st.header("×‘×¨×•×›×™× ×”×‘××™× ×œ×™×•×¢×¥ ×”×¤×™× × ×¡×™ ×”××©×•×œ×‘!")
    st.markdown("""
    ×›×œ×™ ×–×” ×™×¢×–×•×¨ ×œ×š ×œ×§×‘×œ ×ª××•× ×” ×¢×œ ××¦×‘×š ×”×¤×™× × ×¡×™ ×‘×××¦×¢×•×ª ×©×™×œ×•×‘ ×©×œ:
    1.  **×”×¢×œ××ª ×“×•×—×•×ª**: ×“×•×— ×‘× ×§ ×•×“×•×— × ×ª×•× ×™ ××©×¨××™ (××•×¤×¦×™×•× ×œ×™, ××š ××•××œ×¥ ×œ× ×™×ª×•×— ××“×•×™×§).
    2.  **×©××œ×•×Ÿ ×¤×™× × ×¡×™**: ×œ××™×œ×•×™ ×¤×¨×˜×™× × ×•×¡×¤×™× ×¢×œ ×”×›× ×¡×•×ª, ×”×•×¦××•×ª ×•××¦×‘×š ×”×›×œ×œ×™.

    ×‘×¡×™×•× ×”×ª×”×œ×™×š ×ª×§×‘×œ ×¡×™×›×•×, ×¡×™×•×•×’ ×¤×™× × ×¡×™ ×¨××©×•× ×™, ×•×™×–×•××œ×™×–×¦×™×•×ª ×•××¤×©×¨×•×ª ×œ×©×•×—×— ×¢× ×™×•×¢×¥ ×•×™×¨×˜×•××œ×™.
    """)
    if st.button("×”×ª×—×œ ×‘×”×¢×œ××ª ×§×‘×¦×™× (××•××œ×¥)", key="start_with_files"):
        st.session_state.app_stage = "file_upload"
        st.rerun()
    if st.button("×”×ª×—×œ ×™×©×™×¨×•×ª ×¢× ×”×©××œ×•×Ÿ ×”×¤×™× × ×¡×™", key="start_with_questionnaire"):
        # Reset only questionnaire state if skipping files
        st.session_state.questionnaire_stage = 0
        st.session_state.answers = {}
        st.session_state.classification_details = {}
        st.session_state.total_debt_from_credit_report = None # Clear derived debt if skipping file step
        st.session_state.app_stage = "questionnaire"
        st.session_state.chat_messages = [] # Clear chat history
        st.rerun()


elif st.session_state.app_stage == "file_upload":
    st.header("×©×œ×‘ 1: ×”×¢×œ××ª ×“×•×—×•×ª")

    bank_type_options = ["×œ×œ× ×“×•×— ×‘× ×§", "×”×¤×•×¢×œ×™×", "×“×™×¡×§×•× ×˜", "×œ××•××™"]
    current_bank_type_index = bank_type_options.index(st.session_state.bank_type_selected) if st.session_state.bank_type_selected in bank_type_options else 0
    st.session_state.bank_type_selected = st.selectbox(
        "×‘×—×¨ ×¡×•×’ ×“×•×— ×‘× ×§:",
        bank_type_options,
        index=current_bank_type_index,
        key="bank_type_selector_main"
    )

    uploaded_bank_file = None
    if st.session_state.bank_type_selected != "×œ×œ× ×“×•×— ×‘× ×§":
        uploaded_bank_file = st.file_uploader(f"×”×¢×œ×” ×“×•×— ×‘× ×§ ({st.session_state.bank_type_selected}) (×§×•×‘×¥ PDF)", type="pdf", key="bank_pdf_uploader_main")
        if uploaded_bank_file and st.session_state.get('uploaded_bank_file_name') != uploaded_bank_file.name:
             # Clear previously processed bank data if a new file is uploaded
             st.session_state.df_bank_uploaded = pd.DataFrame()
             st.session_state.uploaded_bank_file_name = uploaded_bank_file.name
             st.info(f"×”×§×•×‘×¥ {uploaded_bank_file.name} ×”×•×¢×œ×” ×‘×”×¦×œ×—×”. ×œ×—×¥ ×¢×œ '×¢×‘×“ ×§×‘×¦×™×' ×œ×¢×™×‘×•×“.")
        elif not uploaded_bank_file:
             st.session_state.uploaded_bank_file_name = None

    uploaded_credit_file = st.file_uploader("×”×¢×œ×” ×“×•×— × ×ª×•× ×™ ××©×¨××™ (×§×•×‘×¥ PDF) (××•××œ×¥)", type="pdf", key="credit_pdf_uploader_main")
    if uploaded_credit_file and st.session_state.get('uploaded_credit_file_name') != uploaded_credit_file.name:
         st.session_state.df_credit_uploaded = pd.DataFrame()
         st.session_state.total_debt_from_credit_report = None
         st.session_state.uploaded_credit_file_name = uploaded_credit_file.name
         st.info(f"×”×§×•×‘×¥ {uploaded_credit_file.name} ×”×•×¢×œ×” ×‘×”×¦×œ×—×”. ×œ×—×¥ ×¢×œ '×¢×‘×“ ×§×‘×¦×™×' ×œ×¢×™×‘×•×“.")
    elif not uploaded_credit_file:
         st.session_state.uploaded_credit_file_name = None


    if st.button("×¢×‘×“ ×§×‘×¦×™× ×•×”××©×š ×œ×©××œ×•×Ÿ", key="process_files_button"):
        logging.info("Processing uploaded files...")
        processed_bank = False
        processed_credit = False
        error_processing = False

        with st.spinner("××¢×‘×“ ×§×‘×¦×™×..."):
            # Process Bank File
            st.session_state.df_bank_uploaded = pd.DataFrame() # Reset before processing new file
            if uploaded_bank_file is not None and st.session_state.bank_type_selected != "×œ×œ× ×“×•×— ×‘× ×§":
                try:
                    bank_file_bytes = uploaded_bank_file.getvalue()
                    parser_func = None
                    if st.session_state.bank_type_selected == "×”×¤×•×¢×œ×™×": parser_func = extract_transactions_from_pdf_hapoalim
                    elif st.session_state.bank_type_selected == "×œ××•××™": parser_func = extract_leumi_transactions_line_by_line
                    elif st.session_state.bank_type_selected == "×“×™×¡×§×•× ×˜": parser_func = extract_and_parse_discont_pdf

                    if parser_func:
                        st.session_state.df_bank_uploaded = parser_func(bank_file_bytes, uploaded_bank_file.name)

                    if st.session_state.df_bank_uploaded.empty:
                        st.warning(f"×œ× ×”×¦×œ×—× ×• ×œ×—×œ×¥ × ×ª×•× ×™× ××“×•×— ×”×‘× ×§ ({st.session_state.bank_type_selected}). ×× × ×•×•×“×/×™ ×©×”×§×•×‘×¥ ×ª×§×™×Ÿ ×•×”×¤×•×¨××˜ × ×ª××š.")
                        error_processing = True
                    else:
                        st.success(f"×“×•×— ×‘× ×§ ({st.session_state.bank_type_selected}) ×¢×•×‘×“ ×‘×”×¦×œ×—×”!")
                        processed_bank = True
                except Exception as e:
                    logging.error(f"Error processing bank file {uploaded_bank_file.name}: {e}", exc_info=True)
                    st.error(f"××™×¨×¢×” ×©×’×™××” ×‘×¢×ª ×¢×™×‘×•×“ ×“×•×— ×”×‘× ×§: {e}")
                    error_processing = True


            # Process Credit File
            st.session_state.df_credit_uploaded = pd.DataFrame() # Reset before processing new file
            st.session_state.total_debt_from_credit_report = None # Reset
            if uploaded_credit_file is not None:
                try:
                    credit_file_bytes = uploaded_credit_file.getvalue()
                    st.session_state.df_credit_uploaded = extract_credit_data_final_v13(credit_file_bytes, uploaded_credit_file.name)
                    if st.session_state.df_credit_uploaded.empty:
                        st.warning("×œ× ×”×¦×œ×—× ×• ×œ×—×œ×¥ × ×ª×•× ×™× ××“×•×— ×”××©×¨××™. ×× × ×•×•×“×/×™ ×©×”×§×•×‘×¥ ×ª×§×™×Ÿ.")
                        error_processing = True
                    else:
                        st.success("×“×•×— × ×ª×•× ×™ ××©×¨××™ ×¢×•×‘×“ ×‘×”×¦×œ×—×”!")
                        processed_credit = True
                        if '×™×ª×¨×ª ×—×•×‘' in st.session_state.df_credit_uploaded.columns:
                            total_debt = st.session_state.df_credit_uploaded['×™×ª×¨×ª ×—×•×‘'].fillna(0).sum()
                            st.session_state.total_debt_from_credit_report = total_debt
                            st.info(f"×¡×š ×™×ª×¨×ª ×”×—×•×‘ ×©×—×•×©×‘×” ××“×•×— ×”××©×¨××™: {st.session_state.total_debt_from_credit_report:,.0f} â‚ª")
                        else:
                            st.warning("×¢××•×“×ª '×™×ª×¨×ª ×—×•×‘' ×œ× × ××¦××” ×‘×“×•×— ×”××©×¨××™ ×”××¢×•×‘×“.")

                except Exception as e:
                    logging.error(f"Error processing credit file {uploaded_credit_file.name}: {e}", exc_info=True)
                    st.error(f"××™×¨×¢×” ×©×’×™××” ×‘×¢×ª ×¢×™×‘×•×“ ×“×•×— × ×ª×•× ×™ ×”××©×¨××™: {e}")
                    error_processing = True

        # Move to questionnaire regardless of processing outcome
        if error_processing:
            st.warning("×”×™×• ×©×’×™××•×ª ×‘×¢×™×‘×•×“ ×—×œ×§ ××”×§×‘×¦×™×. ×”× ×™×ª×•×— ×¢×©×•×™ ×œ×”×™×•×ª ×—×œ×§×™.")

        st.session_state.app_stage = "questionnaire"
        st.session_state.questionnaire_stage = 0
        st.session_state.chat_messages = [] # Clear chat history when starting new questionnaire/analysis
        st.rerun()

    if st.button("×“×œ×’ ×¢×œ ×”×¢×œ××ª ×§×‘×¦×™× ×•×”××©×š ×œ×©××œ×•×Ÿ", key="skip_files_button"):
        logging.info("Skipping file upload and proceeding to questionnaire.")
        st.session_state.df_bank_uploaded = pd.DataFrame()
        st.session_state.df_credit_uploaded = pd.DataFrame()
        st.session_state.total_debt_from_credit_report = None
        st.session_state.bank_type_selected = "×œ×œ× ×“×•×— ×‘× ×§"
        st.session_state.uploaded_bank_file_name = None
        st.session_state.uploaded_credit_file_name = None

        st.session_state.app_stage = "questionnaire"
        st.session_state.questionnaire_stage = 0
        st.session_state.chat_messages = []
        st.rerun()


elif st.session_state.app_stage == "questionnaire":
    st.header("×©×œ×‘ 2: ×©××œ×•×Ÿ ×¤×™× × ×¡×™")
    st.markdown("×× × ×¢× ×”/×™ ×¢×œ ×”×©××œ×•×ª ×”×‘××•×ª ×›×“×™ ×œ×¢×–×•×¨ ×œ× ×• ×œ×”×‘×™×Ÿ ×˜×•×‘ ×™×•×ª×¨ ××ª ××¦×‘×š ×”×¤×™× × ×¡×™.")

    q_stage = st.session_state.questionnaire_stage

    # --- Questionnaire Stages ---

    # Stage 0: Initial Questions
    if q_stage == 0:
        st.subheader("×—×œ×§ ×': ×©××œ×•×ª ×¤×ª×™×—×”")
        st.session_state.answers['q1_unusual_event'] = st.text_area("1. ×”×× ×§×¨×” ××©×”×• ×—×¨×™×’ ×©×‘×’×œ×œ×• ×¤× ×™×ª?", value=st.session_state.answers.get('q1_unusual_event', ''), key="q_s0_q1")
        st.session_state.answers['q2_other_funding'] = st.text_area("2. ×”×× ×™×© ××§×•×¨×•×ª ××™××•×Ÿ ××—×¨×™× ×©×‘×“×§×ª?", value=st.session_state.answers.get('q2_other_funding', ''), key="q_s0_q2")

        existing_loans_bool_key = 'q3_existing_loans_bool_radio'
        default_loan_bool_index = ("×œ×","×›×Ÿ").index(st.session_state.answers.get(existing_loans_bool_key, '×œ×'))
        st.session_state.answers[existing_loans_bool_key] = st.radio(
            "3. ×”×× ×§×™×™××•×ª ×”×œ×•×•××•×ª × ×•×¡×¤×•×ª (×œ× ××©×›× ×ª×)?",
            ("×›×Ÿ", "×œ×"),
            index=default_loan_bool_index,
            key="q_s0_q3_bool"
        )
        if st.session_state.answers[existing_loans_bool_key] == "×›×Ÿ":
            st.session_state.answers['q3_loan_repayment_amount'] = st.number_input(
                "××” ×’×•×‘×” ×”×”×—×–×¨ ×”×—×•×“×©×™ ×”×›×•×œ×œ ×¢×œ×™×”×Ÿ?",
                min_value=0.0, value=float(st.session_state.answers.get('q3_loan_repayment_amount', 0.0)), step=100.0, key="q_s0_q3_amount"
            )
        else: st.session_state.answers['q3_loan_repayment_amount'] = 0.0

        balanced_bool_key = 'q4_financially_balanced_bool_radio'
        default_balanced_index = ("×›×Ÿ","×‘×¢×¨×š","×œ×").index(st.session_state.answers.get(balanced_bool_key, '×›×Ÿ'))
        st.session_state.answers[balanced_bool_key] = st.radio(
            "4. ×”×× ××ª× ×××•×–× ×™× ×›×œ×›×œ×™×ª ×›×¨×’×¢ (×”×›× ×¡×•×ª ××›×¡×•×ª ×”×•×¦××•×ª)?",
            ("×›×Ÿ", "×‘×¢×¨×š", "×œ×"),
            index=default_balanced_index,
            key="q_s0_q4_bool"
        )
        st.session_state.answers['q4_situation_change_next_year'] = st.text_area("×”×× ×”××¦×‘ ×”×›×œ×›×œ×™ ×¦×¤×•×™ ×œ×”×©×ª× ×•×ª ××©××¢×•×ª×™×ª ×‘×©× ×” ×”×§×¨×•×‘×” (×œ×—×™×•×‘ ××• ×œ×©×œ×™×œ×”)?", value=st.session_state.answers.get('q4_situation_change_next_year', ''), key="q_s0_q4_change")

        if st.button("×”×‘×", key="q_s0_next"):
            st.session_state.questionnaire_stage += 1
            st.rerun()

    # Stage 1: Income
    elif q_stage == 1:
        st.subheader("×—×œ×§ ×‘': ×”×›× ×¡×•×ª (× ×˜×• ×—×•×“×©×™)")
        st.session_state.answers['income_employee'] = st.number_input("×”×›× ×¡×ª×š (× ×˜×•):", min_value=0.0, value=float(st.session_state.answers.get('income_employee', 0.0)), step=100.0, key="q_s1_inc_emp")
        st.session_state.answers['income_partner'] = st.number_input("×”×›× ×¡×ª ×‘×Ÿ/×‘×ª ×”×–×•×’ (× ×˜×•):", min_value=0.0, value=float(st.session_state.answers.get('income_partner', 0.0)), step=100.0, key="q_s1_inc_partner")
        st.session_state.answers['income_other'] = st.number_input("×”×›× ×¡×•×ª × ×•×¡×¤×•×ª (×§×¦×‘××•×ª, ×©×›×¨ ×“×™×¨×” ×•×›×•'):", min_value=0.0, value=float(st.session_state.answers.get('income_other', 0.0)), step=100.0, key="q_s1_inc_other")

        total_net_income = sum(float(st.session_state.answers.get(k,0.0)) for k in ['income_employee','income_partner','income_other'])
        st.session_state.answers['total_net_income'] = total_net_income
        st.metric("×¡×š ×”×›× ×¡×•×ª × ×˜×• (×—×•×“×©×™):", f"{total_net_income:,.0f} â‚ª")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("×”×§×•×“×", key="q_s1_prev"): st.session_state.questionnaire_stage -= 1; st.rerun()
        with col2:
            if st.button("×”×‘×", key="q_s1_next"): st.session_state.questionnaire_stage += 1; st.rerun()

    # Stage 2: Fixed Expenses
    elif q_stage == 2:
        st.subheader("×—×œ×§ ×’': ×”×•×¦××•×ª ×§×‘×•×¢×•×ª ×—×•×“×©×™×•×ª")
        st.session_state.answers['expense_rent_mortgage'] = st.number_input("×©×›×™×¨×•×ª / ×”×—×–×¨ ××©×›× ×ª×:", min_value=0.0, value=float(st.session_state.answers.get('expense_rent_mortgage', 0.0)), step=100.0, key="q_s2_exp_rent")
        default_debt_repayment = float(st.session_state.answers.get('q3_loan_repayment_amount', 0.0))
        st.session_state.answers['expense_debt_repayments'] = st.number_input(
            "×”×—×–×¨×™ ×”×œ×•×•××•×ª × ×•×¡×¤×•×ª (×œ× ××©×›× ×ª×, ×›×•×œ×œ ×›×¨×˜×™×¡×™ ××©×¨××™ ×× ×™×© ×”×—×–×¨ ×§×‘×•×¢):",
            min_value=0.0, value=float(st.session_state.answers.get('expense_debt_repayments', default_debt_repayment)), step=100.0, key="q_s2_exp_debt"
        )
        st.session_state.answers['expense_alimony_other'] = st.number_input("××–×•× ×•×ª / ×”×•×¦××•×ª ×§×‘×•×¢×•×ª ×’×“×•×œ×•×ª ××—×¨×•×ª (×œ××©×œ: ×—×¡×›×•×Ÿ ×§×‘×•×¢, ×‘×™×˜×•×—×™× ×’×‘×•×”×™×):", min_value=0.0, value=float(st.session_state.answers.get('expense_alimony_other', 0.0)), step=100.0, key="q_s2_exp_alimony")

        total_fixed_expenses = sum(float(st.session_state.answers.get(k,0.0)) for k in ['expense_rent_mortgage','expense_debt_repayments','expense_alimony_other'])
        st.session_state.answers['total_fixed_expenses'] = total_fixed_expenses
        st.metric("×¡×š ×”×•×¦××•×ª ×§×‘×•×¢×•×ª:", f"{total_fixed_expenses:,.0f} â‚ª")

        total_net_income = float(st.session_state.answers.get('total_net_income', 0.0))
        monthly_balance = total_net_income - total_fixed_expenses
        st.session_state.answers['monthly_balance'] = monthly_balance
        st.metric("×™×ª×¨×” ×¤× ×•×™×” ×—×•×“×©×™×ª (×”×›× ×¡×•×ª ×¤×—×•×ª ×§×‘×•×¢×•×ª):", f"{monthly_balance:,.0f} â‚ª")
        if monthly_balance < 0: st.warning("×©×™××• ×œ×‘: ×”×”×•×¦××•×ª ×”×§×‘×•×¢×•×ª ×’×‘×•×”×•×ª ××”×”×›× ×¡×•×ª × ×˜×•.")

        col1, col2 = st.columns(2)
        with col1:
            if st.button("×”×§×•×“×", key="q_s2_prev"): st.session_state.questionnaire_stage -= 1; st.rerun()
        with col2:
            if st.button("×”×‘×", key="q_s2_next"): st.session_state.questionnaire_stage += 1; st.rerun()

    # Stage 3: Total Debts & Arrears
    elif q_stage == 3:
        st.subheader("×—×œ×§ ×“': ×—×•×‘×•×ª ×•×¤×™×’×•×¨×™×")

        default_total_debt = float(st.session_state.answers.get('total_debt_amount', 0.0))
        if st.session_state.total_debt_from_credit_report is not None:
            default_total_debt = st.session_state.total_debt_from_credit_report
            st.info(f"×¡×š ×™×ª×¨×ª ×”×—×•×‘ ×©×—×•×©×‘×” ××“×•×— ×”××©×¨××™ ×©×”×•×¢×œ×” ×”×•×: {st.session_state.total_debt_from_credit_report:,.0f} â‚ª. **× ×™×ª×Ÿ ×œ×¢×“×›×Ÿ ××ª ×”×¡×›×•× ×œ××˜×” ×× ×§×™×™××™× ×—×•×‘×•×ª × ×•×¡×¤×™× ×©×œ× ××•×¤×™×¢×™× ×‘×“×•×—.**")
        else:
             st.info("×× × ×”×–×Ÿ/×™ ××ª ×¡×š ×›×œ ×”×—×•×‘×•×ª ×”×§×™×™××™× (×œ××¢×˜ ××©×›× ×ª×).")


        st.session_state.answers['total_debt_amount'] = st.number_input(
            "××” ×”×™×§×£ ×”×—×•×‘×•×ª ×”×›×•×œ×œ ×©×œ×š (×œ××¢×˜ ××©×›× ×ª×)?",
            min_value=0.0, value=float(st.session_state.answers.get('total_debt_amount', default_total_debt)), step=100.0, key="q_s3_total_debt"
        )

        arrears_key = 'arrears_collection_proceedings_radio'
        default_arrears_index = ("×œ×","×›×Ÿ").index(st.session_state.answers.get(arrears_key, '×œ×'))
        st.session_state.answers[arrears_key] = st.radio(
            "×”×× ×§×™×™××™× ×¤×™×’×•×¨×™× ××©××¢×•×ª×™×™× ×‘×ª×©×œ×•××™× ××• ×”×œ×™×›×™ ×’×‘×™×™×” ×¤×¢×™×œ×™× × ×’×“×š?",
            ("×›×Ÿ", "×œ×"),
            index=default_arrears_index,
            key="q_s3_arrears"
        )

        col1, col2 = st.columns(2)
        with col1:
            if st.button("×”×§×•×“×", key="q_s3_prev"): st.session_state.questionnaire_stage -= 1; st.rerun()
        with col2:
            if st.button("×¡×™×•× ×©××œ×•×Ÿ ×•×§×‘×œ×ª ×¡×™×›×•×", key="q_s3_next_finish"):
                current_total_debt = float(st.session_state.answers.get('total_debt_amount', 0.0))
                current_total_net_income = float(st.session_state.answers.get('total_net_income', 0.0))

                annual_income = current_total_net_income * 12
                st.session_state.answers['annual_income'] = annual_income

                if annual_income > 0:
                     st.session_state.answers['debt_to_income_ratio'] = current_total_debt / annual_income
                else:
                     st.session_state.answers['debt_to_income_ratio'] = float('inf') if current_total_debt > 0 else 0.0

                ratio = st.session_state.answers['debt_to_income_ratio']
                arrears_exist = st.session_state.answers.get(arrears_key, '×œ×') == '×›×Ÿ'

                classification = "×œ× × ×§×‘×¢"
                description = "×œ× ×”×•×©×œ× ×¡×™×•×•×’ ×¨××©×•× ×™."
                color = "gray"
                next_stage = "summary"

                if arrears_exist:
                    classification = "××“×•×"
                    description = "×§×™×™××™× ×¤×™×’×•×¨×™× ××©××¢×•×ª×™×™× ××• ×”×œ×™×›×™ ×’×‘×™×™×” ×¤×¢×™×œ×™×."
                    color = "red"
                    next_stage = "summary"

                elif ratio < 1:
                    classification = "×™×¨×•×§"
                    description = "×¡×š ×”×—×•×‘ × ××•×š ××©××¢×•×ª×™×ª ××”×”×›× ×¡×” ×”×©× ×ª×™×ª (×¤×—×•×ª ××©× ×ª ×”×›× ×¡×”)."
                    color = "green"
                    next_stage = "summary"

                elif 1 <= ratio <= 2:
                    classification = "×¦×”×•×‘ (×‘×‘×“×™×§×”)"
                    description = "×¡×š ×”×—×•×‘ ×‘×’×•×‘×” ×”×”×›× ×¡×” ×©×œ 1-2 ×©× ×™×."
                    color = "orange"
                    next_stage = 100 # Go to special intermediate stage for Yellow

                else: # ratio > 2
                    classification = "××“×•×"
                    description = "×¡×š ×”×—×•×‘ ×’×‘×•×” ××©××¢×•×ª×™×ª ××”×”×›× ×¡×” ×”×©× ×ª×™×ª (××¢×œ ×©× ×ª×™×™× ×”×›× ×¡×”)."
                    color = "red"
                    next_stage = "summary"

                st.session_state.classification_details = {
                    'classification': classification,
                    'description': description,
                    'color': color
                }

                if next_stage == "summary":
                    st.session_state.app_stage = "summary"
                    st.session_state.questionnaire_stage = -1 # Indicate questionnaire is finished
                else:
                    st.session_state.questionnaire_stage = next_stage

                st.rerun()

    # Stage 100: Intermediate questions for Yellow classification
    elif q_stage == 100:
        st.subheader("×©××œ×•×ª ×”×‘×”×¨×” × ×•×¡×¤×•×ª")
        st.warning(f"×ª×•×¦××•×ª ×¨××©×•× ×™×•×ª: ×™×—×¡ ×”×—×•×‘ ×œ×”×›× ×¡×” ×©×œ×š ×”×•× {st.session_state.answers.get('debt_to_income_ratio', 0.0):.2f}. ({st.session_state.classification_details.get('description')})")

        arrears_exist = st.session_state.answers.get('arrears_collection_proceedings_radio', '×œ×') == '×›×Ÿ'

        if arrears_exist:
             st.error("× ××¦× ×©×§×™×™××™× ×”×œ×™×›×™ ×’×‘×™×™×”. ××¦×‘ ×–×” ××¡×•×•×’ ××•×˜×•××˜×™×ª ×›'××“×•×'.")
             st.session_state.classification_details.update({'classification': "××“×•×", 'description': st.session_state.classification_details.get('description','') + " ×§×™×™××™× ×”×œ×™×›×™ ×’×‘×™×™×”.", 'color': "red"})
             if st.button("×”××©×š ×œ×¡×™×›×•×", key="q_s100_to_summary_red_recheck"):
                 st.session_state.app_stage = "summary"
                 st.session_state.questionnaire_stage = -1
                 st.rerun()
        else:
            total_debt = float(st.session_state.answers.get('total_debt_amount', 0.0))
            fifty_percent_debt = total_debt * 0.5 if total_debt > 0 else 0.0
            st.session_state.answers['can_raise_50_percent_radio'] = st.radio(
                f"×”×× ×ª×•×›×œ/×™ ×œ×’×™×™×¡ ×¡×›×•× ×”×©×•×•×” ×œ×›-50% ××¡×š ×”×—×•×‘×•×ª ×”×œ× ××’×•×‘×™× ×‘××©×›× ×ª× ({fifty_percent_debt:,.0f} â‚ª) ×××§×•×¨×•×ª ×ª××™×›×” (××©×¤×—×”, ×—×‘×¨×™×, ××™××•×© × ×›×¡×™×) ×ª×•×š ×–××Ÿ ×¡×‘×™×¨ (×¢×“ ××¡×¤×¨ ×—×•×“×©×™×)?",
                ("×›×Ÿ", "×œ×"),
                index=("×œ×","×›×Ÿ").index(st.session_state.answers.get('can_raise_50_percent_radio', '×œ×')),
                key="q_s100_q_raise_funds"
            )
            if st.button("×”××©×š ×œ×¡×™×›×•×", key="q_s100_to_summary_yellow_check"):
                if st.session_state.answers.get('can_raise_50_percent_radio', '×œ×') == "×›×Ÿ":
                    st.session_state.classification_details.update({'classification': "×¦×”×•×‘", 'description': st.session_state.classification_details.get('description','') + " ××™×Ÿ ×”×œ×™×›×™ ×’×‘×™×™×” ×•×™×© ×™×›×•×œ×ª ×œ×’×™×™×¡ 50% ××”×—×•×‘ ×××§×•×¨×•×ª ×ª××™×›×”.", 'color': "orange"})
                else:
                    st.session_state.classification_details.update({'classification': "×¦×”×•×‘+", 'description': st.session_state.classification_details.get('description','') + " ××™×Ÿ ×”×œ×™×›×™ ×’×‘×™×™×” ××š ××™×Ÿ ×™×›×•×œ×ª ××™×™×“×™×ª ×œ×’×™×™×¡ ×¡×›×•× ××©××¢×•×ª×™ ×××§×•×¨×•×ª ×ª××™×›×”.", 'color': "orange"}) # Maybe make this "×¦×”×•×‘+" or keep red? Let's use orange for now but add nuance. Or maybe it *is* red without ability to raise funds? Revert to Red if no ability to raise funds seems more appropriate for actionability.

                # Re-evaluating classification for yellow based on ability to raise funds (simplified)
                if st.session_state.answers.get('can_raise_50_percent_radio', '×œ×') == "×›×Ÿ":
                     st.session_state.classification_details.update({'classification': "×¦×”×•×‘", 'description': "×¡×š ×”×—×•×‘ ×‘×’×•×‘×” ×”×”×›× ×¡×” ×©×œ 1-2 ×©× ×™×, ××™×Ÿ ×”×œ×™×›×™ ×’×‘×™×™×” ×•×™×© ×™×›×•×œ×ª ×œ×’×™×™×¡ 50% ××”×—×•×‘ ×××§×•×¨×•×ª ×ª××™×›×”.", 'color': "orange"})
                else:
                     st.session_state.classification_details.update({'classification': "××“×•×", 'description': "×¡×š ×”×—×•×‘ ×‘×’×•×‘×” ×”×”×›× ×¡×” ×©×œ 1-2 ×©× ×™×, ××™×Ÿ ×”×œ×™×›×™ ×’×‘×™×™×” ××š **××™×Ÿ** ×™×›×•×œ×ª ×œ×’×™×™×¡ 50% ××”×—×•×‘ ×××§×•×¨×•×ª ×ª××™×›×”.", 'color': "red"}) # Leaning towards red if significant external help isn't possible for a yellow case

                st.session_state.app_stage = "summary"
                st.session_state.questionnaire_stage = -1
                st.rerun()

        if st.button("×—×–×•×¨ ×œ×©×œ×‘ ×”×§×•×“× ×‘×©××œ×•×Ÿ", key="q_s100_prev"):
            st.session_state.questionnaire_stage = 3; st.rerun()


elif st.session_state.app_stage == "summary":
    st.header("×©×œ×‘ 3: ×¡×™×›×•×, ×•×™×–×•××œ×™×–×¦×™×•×ª ×•×™×™×¢×•×¥")
    st.markdown("×œ×”×œ×Ÿ ×¡×™×›×•× ×”× ×ª×•× ×™× ×©××¡×¤× ×• ×•×”× ×™×ª×•×— ×”×¨××©×•× ×™.")

    # Retrieve calculated metrics
    total_net_income_ans = float(st.session_state.answers.get('total_net_income', 0.0))
    total_fixed_expenses_ans = float(st.session_state.answers.get('expense_rent_mortgage', 0.0)) + float(st.session_state.answers.get('expense_debt_repayments', 0.0)) + float(st.session_state.answers.get('expense_alimony_other', 0.0))
    monthly_balance_ans = total_net_income_ans - total_fixed_expenses_ans
    total_debt_amount_ans = float(st.session_state.answers.get('total_debt_amount', 0.0))
    annual_income_ans = total_net_income_ans * 12
    debt_to_income_ratio_ans = (total_debt_amount_ans / annual_income_ans) if annual_income_ans > 0 else (float('inf') if total_debt_amount_ans > 0 else 0.0)


    st.subheader("ğŸ“Š ×¡×™×›×•× × ×ª×•× ×™× ×¤×™× × ×¡×™×™×")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("ğŸ’° ×¡×š ×”×›× ×¡×•×ª × ×˜×• (×—×•×“×©×™)", f"{total_net_income_ans:,.0f} â‚ª")
        st.metric("ğŸ’¸ ×¡×š ×”×•×¦××•×ª ×§×‘×•×¢×•×ª (×—×•×“×©×™)", f"{total_fixed_expenses_ans:,.0f} â‚ª")

    with col2:
        st.metric("ğŸ“Š ×™×ª×¨×” ×¤× ×•×™×” (×—×•×“×©×™)", f"{monthly_balance_ans:,.0f} â‚ª")
        st.metric("ğŸ“ˆ ×”×›× ×¡×” ×©× ×ª×™×ª", f"{annual_income_ans:,.0f} â‚ª")

    with col3:
        st.metric("ğŸ¦ ×¡×š ×—×•×‘×•×ª (×œ×œ× ××©×›× ×ª×)", f"{total_debt_amount_ans:,.0f} â‚ª")
        # Check if credit report debt exists and is different from questionnaire debt
        if st.session_state.total_debt_from_credit_report is not None and abs(st.session_state.total_debt_from_credit_report - total_debt_amount_ans) > 1:
             st.caption(f"(××“×•×— ××©×¨××™ ×©× ×•×ª×—: {st.session_state.total_debt_from_credit_report:,.0f} â‚ª)")
        st.metric("âš–ï¸ ×™×—×¡ ×—×•×‘ ×œ×”×›× ×¡×” ×©× ×ª×™×ª", f"{debt_to_income_ratio_ans:.2%}")


    # Display classification and recommendations
    st.subheader("×¡×™×•×•×’ ××¦×‘ ×¤×™× × ×¡×™ ×•×”××œ×¦×” ×¨××©×•× ×™×ª:")
    classification = st.session_state.classification_details.get('classification', "×œ× × ×§×‘×¢")
    description = st.session_state.classification_details.get('description', "")
    color = st.session_state.classification_details.get('color', "gray")

    if color == "green":
        st.success(f"ğŸŸ¢ **×¡×™×•×•×’: {classification}**")
        st.markdown("""
        **××¦×‘ ×™×¦×™×‘.** ×™×—×¡ ×”×—×•×‘ ×œ×”×›× ×¡×” × ××•×š. ×–×”×• ××¦×‘ ×”×××¤×©×¨ ×’××™×©×•×ª ×¤×™× × ×¡×™×ª.
        * **×”××œ×¦×” ×¨××©×•× ×™×ª:** ×”××©×š/×™ ×‘× ×™×”×•×œ ×¤×™× × ×¡×™ ××—×¨××™. ×›×“××™ ×œ×©×§×•×œ ×”×’×“×œ×ª ×—×™×¡×›×•×Ÿ ××• ×”×©×§×¢×•×ª. ×“×•×— ×”××©×¨××™ ×™×›×•×œ ×œ×¢×–×•×¨ ×œ×”×‘×™×Ÿ ××ª ×”××’×‘×œ×•×ª ×”×§×™×™××•×ª ×•×œ×©×¤×¨ ×ª× ××™× ×¢×ª×™×“×™×™×.
        """)
    elif color == "orange":
        st.warning(f"ğŸŸ¡ **×¡×™×•×•×’: {classification}**")
        st.markdown("""
        **××¦×‘ ×”×“×•×¨×© ×‘×“×™×§×” ×•×ª×©×•××ª ×œ×‘.** ×™×—×¡ ×”×—×•×‘ ×œ×”×›× ×¡×” ××¢×™×“ ×¢×œ ×¤×•×˜× ×¦×™××œ ×§×•×©×™, ××š ××™×Ÿ ×”×œ×™×›×™ ×’×‘×™×™×” ×•×™×© ×™×›×•×œ×ª ×œ×’×™×™×¡ ×¡×›×•× ××©××¢×•×ª×™ ×‘×—×™×¨×•×.
        * **×”××œ×¦×” ×¨××©×•× ×™×ª:** ××•××œ×¥ ×œ×‘×—×•×Ÿ ×œ×¢×•××§ ××ª ×¤×™×¨×•×˜ ×”×—×•×‘×•×ª (×‘×“×•×— ×”××©×¨××™) ×•×”×”×•×¦××•×ª (×“×¨×š ×“×•×— ×”×‘× ×§ ××• ××¢×§×‘ ××™×©×™). ×‘× ×”/×™ ×ª×•×›× ×™×ª ×¤×¢×•×œ×” ×××•×§×“×ª ×œ×¦××¦×•× ×”×—×•×‘×•×ª. ×”×’×“×œ×ª ×”×›× ×¡×•×ª ××• ×§×™×¦×•×¥ ×‘×”×•×¦××•×ª ×œ× ×—×™×•× ×™×•×ª ×™×›×•×œ×™× ×œ×¢×–×•×¨ ××©××¢×•×ª×™×ª. ×”×©×ª××©/×™ ×‘×¦'××˜ ×›×“×™ ×œ×‘×§×© ×¨×¢×™×•× ×•×ª ×œ× ×™×”×•×œ ×ª×§×¦×™×‘ ××• ×¡×“×¨ ×¢×“×™×¤×•×™×•×ª ×‘×—×•×‘×•×ª.
        """)
    elif color == "red":
        st.error(f"ğŸ”´ **×¡×™×•×•×’: {classification}**")
        st.markdown("""
        **××¦×‘ ×§×©×” ×”×“×•×¨×© ×”×ª×¢×¨×‘×•×ª ××™×™×“×™×ª.** ×™×—×¡ ×”×—×•×‘ ×œ×”×›× ×¡×” ×’×‘×•×” ××• ×©×§×™×™××™× ×”×œ×™×›×™ ×’×‘×™×™×” ××• ×©××™×Ÿ ×™×›×•×œ×ª ×œ×’×™×™×¡ ×¡×›×•× ××©××¢×•×ª×™ ×‘×—×™×¨×•×. ×”××¦×‘ ×“×•×¨×© ×˜×™×¤×•×œ ×“×—×•×£.
        * **×”××œ×¦×” ×¨××©×•× ×™×ª:** ××œ ×ª×“×—×”/×™ ×–××ª! ×¤× ×”/×™ ×‘×”×§×“× ×œ×™×™×¢×•×¥ ××§×¦×•×¢×™ ×‘×ª×—×•× ×›×œ×›×œ×ª ×”××©×¤×—×” ×•×”×—×•×‘×•×ª. ××¨×’×•× ×™× ×›××• "×¤×¢××•× ×™×" ××• ×™×•×¢×¦×™× ×¤×¨×˜×™×™× ××•××—×™× ×™×›×•×œ×™× ×œ×¢×–×•×¨ ×‘×‘× ×™×™×ª ×ª×•×›× ×™×ª ×—×™×¨×•×, × ×™×”×•×œ ××©× ×•××ª×Ÿ ×¢× × ×•×©×™×, ×•×‘×—×™× ×ª ××¤×©×¨×•×™×•×ª ××©×¤×˜×™×•×ª ×× × ×“×¨×©. ×—×©×•×‘ ×œ×”×‘×™×Ÿ ××ª ××œ×•× ×”×™×§×£ ×”×—×•×‘ ×•×œ×”×¤×¡×™×§ ×œ×¦×‘×•×¨ ×—×•×‘ ×—×“×©.
        """)
    else:
         st.info(f"âš« **×¡×™×•×•×’: {classification}**")
         st.markdown("""
         **×”×¡×™×•×•×’ ×œ× ×”×•×©×œ×.** ×™×™×ª×›×Ÿ ×©×—×¡×¨×™× × ×ª×•× ×™× ×‘×©××œ×•×Ÿ.
         * **×”××œ×¦×” ×¨××©×•× ×™×ª:** ×× × ×”×©×œ×/×™ ××ª ×”×©××œ×•×Ÿ ×›×“×™ ×œ×§×‘×œ ×¡×™×•×•×’ ×•×”××œ×¦×” ×¨××©×•× ×™×ª.
         """)

    st.markdown("---")
    st.subheader("ğŸ¨ ×•×™×–×•××œ×™×–×¦×™×•×ª ××¨×›×–×™×•×ª")

    # Visualization 1: Debt Breakdown from Credit Report (Pie Chart)
    if not st.session_state.df_credit_uploaded.empty and '×¡×•×’ ×¢×¡×§×”' in st.session_state.df_credit_uploaded.columns and '×™×ª×¨×ª ×—×•×‘' in st.session_state.df_credit_uploaded.columns:
        df_credit_cleaned = st.session_state.df_credit_uploaded.copy()
        df_credit_cleaned['×™×ª×¨×ª ×—×•×‘_numeric'] = pd.to_numeric(df_credit_cleaned['×™×ª×¨×ª ×—×•×‘'], errors='coerce').fillna(0)
        debt_summary = df_credit_cleaned.groupby("×¡×•×’ ×¢×¡×§×”")["×™×ª×¨×ª ×—×•×‘_numeric"].sum().reset_index()
        debt_summary = debt_summary[debt_summary['×™×ª×¨×ª ×—×•×‘_numeric'] > 0]

        if not debt_summary.empty:
            fig_debt_pie = px.pie(
                debt_summary,
                values='×™×ª×¨×ª ×—×•×‘_numeric',
                names='×¡×•×’ ×¢×¡×§×”',
                title='×¤×™×¨×•×˜ ×™×ª×¨×•×ª ×—×•×‘ (××“×•×— × ×ª×•× ×™ ××©×¨××™)',
                color_discrete_sequence=px.colors.qualitative.Pastel
            )
            fig_debt_pie.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig_debt_pie, use_container_width=True)
        else:
             st.info("××™×Ÿ × ×ª×•× ×™ ×—×•×‘ ××©××¢×•×ª×™×™× ×‘×“×•×— ×”××©×¨××™ ×œ×”×¦×’×”.")

    # Visualization 2: Debt vs. Income (Bar Chart)
    if total_debt_amount_ans > 0 or annual_income_ans > 0 :
        comparison_data = pd.DataFrame({
            '×§×˜×’×•×¨×™×”': ['×¡×š ×—×•×‘×•×ª (×œ×œ× ××©×›× ×ª×)', '×”×›× ×¡×” ×©× ×ª×™×ª'],
            '×¡×›×•×': [total_debt_amount_ans, annual_income_ans]
        })
        fig_debt_income_bar = px.bar(
            comparison_data,
            x='×§×˜×’×•×¨×™×”',
            y='×¡×›×•×',
            title='×”×©×•×•××ª ×¡×š ×—×•×‘×•×ª ×œ×”×›× ×¡×” ×©× ×ª×™×ª',
            color='×§×˜×’×•×¨×™×”',
            text_auto=True,
            labels={'×§×˜×’×•×¨×™×”': '', '×¡×›×•×': '×¡×›×•× ×‘â‚ª'}
        )
        fig_debt_income_bar.update_layout(yaxis_tickformat='~s')
        st.plotly_chart(fig_debt_income_bar, use_container_width=True)
    else:
         st.info("××™×Ÿ × ×ª×•× ×™ ×—×•×‘ ××• ×”×›× ×¡×” ×œ×”×¦×’×ª ×”×©×•×•××”.")


    # Visualization 3: Bank Balance Trend (Line Chart)
    if not st.session_state.df_bank_uploaded.empty:
        st.subheader(f"××’××ª ×™×ª×¨×ª ×—×©×‘×•×Ÿ ×‘× ×§ ({st.session_state.bank_type_selected})")
        df_bank_plot = st.session_state.df_bank_uploaded.dropna(subset=['Date', 'Balance']).sort_values(by='Date').reset_index(drop=True)
        if not df_bank_plot.empty:
            fig_balance_trend = px.line(
                df_bank_plot,
                x='Date',
                y='Balance',
                title=f'××’××ª ×™×ª×¨×ª ×—×©×‘×•×Ÿ ×‘× ×§',
                markers=True
            )
            fig_balance_trend.update_layout(yaxis_tickformat='~s')
            st.plotly_chart(fig_balance_trend, use_container_width=True)
        else:
             st.info(f"××™×Ÿ × ×ª×•× ×™ ×™×ª×¨×•×ª ×ª×§×™× ×™× ×‘×“×•×— ×”×‘× ×§ ({st.session_state.bank_type_selected}) ×œ×”×¦×’×”.")
    elif st.session_state.bank_type_selected != "×œ×œ× ×“×•×— ×‘× ×§":
        st.info(f"×œ× ×”×•×¢×œ×” ××• ×œ× ×”×¦×œ×—× ×• ×œ×¢×‘×“ ×“×•×— ×‘× ×§ ××¡×•×’ {st.session_state.bank_type_selected}.")
    else:
         st.info("×œ× × ×‘×—×¨ ×¡×•×’ ×“×•×— ×‘× ×§ ××• ×œ× ×”×•×¢×œ×” ×§×•×‘×¥.")


    # Display DataFrames (optional expander)
    with st.expander("×”×¦×’ × ×ª×•× ×™× ×’×•×œ××™×™× ×©×—×•×œ×¦×• ××“×•×—×•×ª ×©×”×•×¢×œ×•"):
        if not st.session_state.df_credit_uploaded.empty:
            st.write("× ×ª×•× ×™ ××©×¨××™ ××—×•×œ×¦×™×:")
            styled_credit_df = st.session_state.df_credit_uploaded.style.format({
                '×’×•×‘×” ××¡×’×¨×ª': "{:,.0f}", '×¡×›×•× ××§×•×¨×™': "{:,.0f}",
                '×™×ª×¨×ª ×—×•×‘': "{:,.0f}", '×™×ª×¨×” ×©×œ× ×©×•×œ××”': "{:,.0f}"
            })
            st.dataframe(styled_credit_df, use_container_width=True)
        else: st.write("×œ× ×”×•×¢×œ×” ××• ×œ× ×¢×•×‘×“ ×“×•×— × ×ª×•× ×™ ××©×¨××™.")

        st.markdown("---")

        if not st.session_state.df_bank_uploaded.empty:
            st.write(f"× ×ª×•× ×™ ×™×ª×¨×•×ª ×‘× ×§ ××—×•×œ×¦×™× ({st.session_state.bank_type_selected}):")
            styled_bank_df = st.session_state.df_bank_uploaded.style.format({"Balance": '{:,.2f}'})
            st.dataframe(styled_bank_df, use_container_width=True)
        else:
             if st.session_state.bank_type_selected != "×œ×œ× ×“×•×— ×‘× ×§": st.write(f"×œ× ×”×•×¢×œ×” ××• ×œ× ×¢×•×‘×“ ×“×•×— ×‘× ×§ ××¡×•×’ {st.session_state.bank_type_selected}.")
             else: st.write("×œ× × ×‘×—×¨ ××• ×”×•×¢×œ×” ×“×•×— ×‘× ×§.")


    st.markdown("---")
    # --- Chatbot Interface ---
    st.header("ğŸ’¬ ×¦'××˜ ×¢× ×™×•×¢×¥ ×¤×™× × ×¡×™ ×•×™×¨×˜×•××œ×™")
    if client:
        st.markdown("×©××œ/×™ ×›×œ ×©××œ×” ×¢×œ ××¦×‘×š ×”×¤×™× × ×¡×™, ×”× ×ª×•× ×™× ×©×”×•×¦×’×•, ××• ×›×œ×›×œ×ª ×”××©×¤×—×”.")

        # Prepare context for chatbot
        financial_context = "×¡×™×›×•× ×”××¦×‘ ×”×¤×™× × ×¡×™ ×©×œ ×”××©×ª××©:\n"
        financial_context += f"- ×¡×š ×”×›× ×¡×•×ª × ×˜×• ×—×•×“×©×™×•×ª (××©××œ×•×Ÿ): {total_net_income_ans:,.0f} â‚ª\n"
        financial_context += f"- ×¡×š ×”×•×¦××•×ª ×§×‘×•×¢×•×ª ×—×•×“×©×™×•×ª (××©××œ×•×Ÿ): {total_fixed_expenses_ans:,.0f} â‚ª\n"
        financial_context += f"- ×××–×Ÿ ×—×•×“×©×™ (×™×ª×¨×” ×¤× ×•×™×”): {monthly_balance_ans:,.0f} â‚ª\n"
        financial_context += f"- ×¡×š ×—×•×‘×•×ª (×œ×œ× ××©×›× ×ª×, ×œ××—×¨ ×©××œ×•×Ÿ ×•××•×œ×™ ×¢×“×›×•×Ÿ ××“×•×—): {total_debt_amount_ans:,.0f} â‚ª\n"

        # Add credit report details if available
        if not st.session_state.df_credit_uploaded.empty and '×™×ª×¨×ª ×—×•×‘' in st.session_state.df_credit_uploaded.columns:
            financial_context += f"  - ××ª×•×›×, ×¡×š ×™×ª×¨×ª ×—×•×‘ ××“×•×— ××©×¨××™ ×©× ×•×ª×—: {st.session_state.total_debt_from_credit_report if st.session_state.total_debt_from_credit_report is not None else '×œ× ×—×•×©×‘':,.0f} â‚ª\n"
            financial_context += "  - ×¤×™×¨×•×˜ ×—×•×‘×•×ª ××“×•×— × ×ª×•× ×™ ××©×¨××™ (×¢×™×§×¨×™):\n"
            df_credit_cleaned = st.session_state.df_credit_uploaded.copy()
            df_credit_cleaned['×™×ª×¨×ª ×—×•×‘'] = pd.to_numeric(df_credit_cleaned['×™×ª×¨×ª ×—×•×‘'], errors='coerce').fillna(0)
            df_credit_cleaned['×™×ª×¨×” ×©×œ× ×©×•×œ××”'] = pd.to_numeric(df_credit_cleaned['×™×ª×¨×” ×©×œ× ×©×•×œ××”'], errors='coerce').fillna(0)

            max_credit_entries_to_list = 15 # Increased limit slightly
            for i, row in df_credit_cleaned.head(max_credit_entries_to_list).iterrows():
                 # Ensure row data is valid before formatting
                 ×¡×•×’_×¢×¡×§×” = row.get('×¡×•×’ ×¢×¡×§×”', '×œ× ×™×“×•×¢')
                 ×©×_×‘× ×§ = row.get('×©× ×‘× ×§/××§×•×¨', '×œ× ×™×“×•×¢')
                 ×™×ª×¨×ª_×—×•×‘ = row['×™×ª×¨×ª ×—×•×‘'] if pd.notna(row['×™×ª×¨×ª ×—×•×‘']) else 0
                 ×™×ª×¨×”_×©×œ×_×©×•×œ××” = row['×™×ª×¨×” ×©×œ× ×©×•×œ××”'] if pd.notna(row['×™×ª×¨×” ×©×œ× ×©×•×œ××”']) else 0
                 financial_context += f"    - {×¡×•×’_×¢×¡×§×”} ×‘{×©×_×‘× ×§}: ×™×ª×¨×ª ×—×•×‘ {×™×ª×¨×ª_×—×•×‘:,.0f} â‚ª (×¤×™×’×•×¨: {×™×ª×¨×”_×©×œ×_×©×•×œ××”:,.0f} â‚ª)\n"

            if len(df_credit_cleaned) > max_credit_entries_to_list:
                financial_context += f"    ... ×•×¢×•×“ {len(df_credit_cleaned) - max_credit_entries_to_list} ×¤×¨×™×˜×™× ×‘×“×•×— ×”××©×¨××™.\n"
        elif st.session_state.get('uploaded_credit_file_name'): # If file was uploaded but processing failed
             financial_context += "- ×“×•×— × ×ª×•× ×™ ××©×¨××™ ×”×•×¢×œ×” ××š ×œ× × ×™×ª×Ÿ ×”×™×” ×œ×—×œ×¥ ××× ×• × ×ª×•× ×™×.\n"
        else:
             financial_context += "- ×œ× ×”×•×¢×œ×” ×“×•×— × ×ª×•× ×™ ××©×¨××™.\n"


        # Add bank balance trend info if available
        if not st.session_state.df_bank_uploaded.empty:
            financial_context += f"- × ×•×ª×— ×“×•×— ×‘× ×§ ××¡×•×’: {st.session_state.bank_type_selected}\n"
            df_bank_plot = st.session_state.df_bank_uploaded.dropna(subset=['Date', 'Balance']).sort_values(by='Date').reset_index(drop=True)
            if not df_bank_plot.empty:
                start_date_str = df_bank_plot['Date'].min().strftime('%d/%m/%Y') if not df_bank_plot['Date'].empty and pd.notna(df_bank_plot['Date'].min()) else '×œ× ×™×“×•×¢'
                end_date_str = df_bank_plot['Date'].max().strftime('%d/%m/%Y') if not df_bank_plot['Date'].empty and pd.notna(df_bank_plot['Date'].max()) else '×œ× ×™×“×•×¢'
                start_balance = df_bank_plot.iloc[0]['Balance'] if not df_bank_plot.empty and pd.notna(df_bank_plot.iloc[0]['Balance']) else np.nan
                end_balance = df_bank_plot.iloc[-1]['Balance'] if not df_bank_plot.empty and pd.notna(df_bank_plot.iloc[-1]['Balance']) else np.nan

                financial_context += f"  - ××’××ª ×™×ª×¨×ª ×—×©×‘×•×Ÿ ×‘× ×§ ×œ×ª×§×•×¤×” ×-{start_date_str} ×¢×“ {end_date_str}:\n"
                financial_context += f"    - ×™×ª×¨×ª ×¤×ª×™×—×”: {start_balance:,.0f} â‚ª\n" if pd.notna(start_balance) else "    - ×™×ª×¨×ª ×¤×ª×™×—×”: ×œ× ×™×“×•×¢\n"
                financial_context += f"    - ×™×ª×¨×ª ×¡×’×™×¨×”: {end_balance:,.0f} â‚ª\n" if pd.notna(end_balance) else "    - ×™×ª×¨×ª ×¡×’×™×¨×”: ×œ× ×™×“×•×¢\n"
                if pd.notna(start_balance) and pd.notna(end_balance):
                     financial_context += f"    - ×©×™× ×•×™ ×‘×ª×§×•×¤×”: {(end_balance - start_balance):,.0f} â‚ª\n"
            else:
                 financial_context += "  - ×œ× × ×™×ª×Ÿ ×œ×—×œ×¥ × ×ª×•× ×™ ××’××” ××“×•×— ×”×‘× ×§.\n"
        elif st.session_state.bank_type_selected != "×œ×œ× ×“×•×— ×‘× ×§": # If bank type was selected but processing failed
             financial_context += f"- ×“×•×— ×‘× ×§ ××¡×•×’ {st.session_state.bank_type_selected} ×”×•×¢×œ×” ××š ×œ× × ×™×ª×Ÿ ×”×™×” ×œ×—×œ×¥ ××× ×• × ×ª×•× ×™×.\n"
        else:
             financial_context += "- ×œ× ×”×•×¢×œ×” ×“×•×— ×‘× ×§.\n"


        financial_context += f"- ×”×›× ×¡×” ×©× ×ª×™×ª: {annual_income_ans:,.0f} â‚ª\n"
        financial_context += f"- ×™×—×¡ ×—×•×‘ ×œ×”×›× ×¡×” ×©× ×ª×™×ª: {debt_to_income_ratio_ans:.2%}\n"
        financial_context += f"- ×¡×™×•×•×’ ××¦×‘ ×¤×™× × ×¡×™ ×¨××©×•× ×™: {classification} ({description})\n"

        financial_context += "\n×ª×©×•×‘×•×ª × ×•×¡×¤×•×ª ××”×©××œ×•×Ÿ:\n"

        # Include relevant questionnaire answers, skipping technical keys or ones already summarized
        # Define a dictionary for mapping internal keys to friendly labels
        friendly_key_map = {
            'q1_unusual_event': '×”×× ×§×¨×” ××©×”×• ×—×¨×™×’ ×©×’×¨× ×œ×¤× ×™×™×”',
            'q2_other_funding': '××§×•×¨×•×ª ××™××•×Ÿ ××—×¨×™× ×©× ×‘×“×§×•',
            'q3_existing_loans_bool_radio': '×§×™×™××•×ª ×”×œ×•×•××•×ª × ×•×¡×¤×•×ª (×œ×œ× ××©×›× ×ª×)',
            'q3_loan_repayment_amount': '×’×•×‘×” ×”×—×–×¨ ×—×•×“×©×™ ×œ×”×œ×•×•××•×ª × ×•×¡×¤×•×ª',
            'q4_financially_balanced_bool_radio': '×××•×–× ×™× ×›×œ×›×œ×™×ª ×›×¨×’×¢',
            'q4_situation_change_next_year': '×©×™× ×•×™ ×¦×¤×•×™ ×‘××¦×‘ ×‘×©× ×” ×”×§×¨×•×‘×”',
            'arrears_collection_proceedings_radio': '×§×™×™××™× ×¤×™×’×•×¨×™×/×”×œ×™×›×™ ×’×‘×™×™×”',
            'can_raise_50_percent_radio': '×™×›×•×œ×ª ×œ×’×™×™×¡ 50% ××”×—×•×‘ ×××§×•×¨×•×ª ×ª××™×›×”',
            # Add other keys if needed and not covered above
        }

        for key, value in st.session_state.answers.items():
            # Skip keys that are already explicitly summarized or are internal calculation results
            if key in ['total_net_income', 'total_fixed_expenses', 'monthly_balance', 'total_debt_amount', 'annual_income', 'debt_to_income_ratio',
                       'income_employee', 'income_partner', 'income_other', 'expense_rent_mortgage', 'expense_debt_repayments', 'expense_alimony_other']:
                continue # Skip raw numbers that are summed up

            display_key = friendly_key_map.get(key, key.replace('_', ' ').strip()) # Get friendly name or default

            # Format value based on its type
            if isinstance(value, (int, float)):
                 financial_context += f"- {display_key}: {value:,.0f}\n" # Format numbers
            elif isinstance(value, str) and value.strip() != "":
                 financial_context += f"- {display_key}: {value}\n" # Add non-empty strings
            # Skip None, empty strings, or booleans already covered by radio button logic

        financial_context += "\n--- ×¡×•×£ ××™×“×¢ ×¢×œ ×”××©×ª××© ---\n"
        # Refined system prompt instructions
        financial_context += "××ª×” ×™×•×¢×¥ ×¤×™× × ×¡×™ ××•××—×” ×œ×›×œ×›×œ×ª ×”××©×¤×—×” ×‘×™×©×¨××œ. ×”××©×ª××© ×”×–×™×Ÿ ×•/××• ×”×¢×œ×” × ×ª×•× ×™× ×¤×™× × ×¡×™×™× ×”××¡×•×›××™× ×œ×¢×™×œ. ×¡×¤×§ ×™×™×¢×•×¥ ×¤×¨×§×˜×™, ×‘×¨×•×¨, ×××¤×ª×™ ×•××•×ª×× ××™×©×™×ª ×¢×œ ×‘×¡×™×¡ ×”× ×ª×•× ×™× ×©×¡×•×¤×§×•. ×¢× ×” ×‘×¢×‘×¨×™×ª ×¨×”×•×˜×”. ×”×©×ª××© ×‘×¡×™×•×•×’ ×”××¦×‘ (×™×¨×•×§/×¦×”×•×‘/××“×•×) ×›×‘×¡×™×¡ ×œ×”××œ×¦×•×ª ×”×¨××©×•× ×™×•×ª ×•×”×¨×—×‘ ×¢×œ×™×”×Ÿ. ×”×ª×™×™×—×¡ ×œ× ×ª×•× ×™× ×”×¡×¤×¦×™×¤×™×™× ×©×¡×•×¤×§×• ××“×•×—×•×ª ××• ××”×©××œ×•×Ÿ ×›×¨×œ×•×•× ×˜×™. ××œ ×ª××¦×™× × ×ª×•× ×™× ××• ××§×•×¨×•×ª ××™××•×Ÿ ×©×œ× ×¦×•×™× ×•. ×× ××™×“×¢ ×—×™×•× ×™ ×œ×©××œ×” ×—×¡×¨ ×‘× ×ª×•× ×™× ×©×¡×•×¤×§×•, ×¦×™×™×Ÿ ×–××ª. ×”×“×’×© ××ª ×¡×š ×”×—×•×‘×•×ª ×•×™×—×¡ ×”×—×•×‘ ×œ×”×›× ×¡×” ×›× ×§×•×“×•×ª ××¨×›×–×™×•×ª. ×¢×–×•×¨ ×œ××©×ª××© ×œ×”×‘×™×Ÿ ××ª ××¦×‘×• ×•×œ×”×ª×•×•×ª ×¦×¢×“×™× ×¨××©×•× ×™× ××¤×©×¨×™×™×."


        # Display chat messages from history
        for message in st.session_state.chat_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # Handle new user input
        if prompt := st.chat_input("×©××œ ××•×ª×™ ×›×œ ×©××œ×” ×¢×œ ××¦×‘×š ×”×¤×™× × ×¡×™ ××• ×›×œ×›×œ×ª ×”××©×¤×—×”..."):
            # Add user message to state and display
            st.session_state.chat_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # Add a temporary assistant placeholder to state immediately
            st.session_state.chat_messages.append({"role": "assistant", "content": ""})
            assistant_message_index = len(st.session_state.chat_messages) - 1

            # Prepare messages for API: system message + all previous messages (excluding the temporary placeholder)
            messages_for_api = [
                {"role": "system", "content": financial_context}
            ] + [{"role": m["role"], "content": m["content"]} for m in st.session_state.chat_messages[:-1]] # Use history *before* the current assistant turn

            # --- ADD LOGGING HERE ---
            logging.info("Messages sent to OpenAI API:")
            logging.info(messages_for_api)
            # ------------------------

            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                full_response = ""
                try:
                    stream = client.chat.completions.create(
                        model="gpt-4o-mini", # Using a more cost-effective model
                        messages=messages_for_api,
                        stream=True
                    )

                    for chunk in stream:
                        if chunk.choices[0].delta.content is not None:
                            full_response += chunk.choices[0].delta.content
                            message_placeholder.markdown(full_response + "â–Œ")

                    message_placeholder.markdown(full_response)

                except APIError as e:
                    logging.error(f"OpenAI API Error (Status Code {e.status_code}): {e.response.text}", exc_info=True)
                    # Check if it's specifically a context length error (status 400, type 'context_length_exceeded')
                    error_detail = "××™×¨×¢×” ×©×’×™××” ×‘×ª×§×©×•×¨×ª ×¢× ×©×™×¨×•×ª ×”×™×™×¢×•×¥ ×”×•×•×™×¨×˜×•××œ×™."
                    if e.status_code == 400 and "'code': 'context_length_exceeded'" in str(e.response.text):
                         error_detail = "×”×”×™×¡×˜×•×¨×™×” ×©×œ ×”×¦'××˜ ×•×¤×¨×˜×™ ×”××¦×‘ ×”×¤×™× × ×¡×™ ××¨×•×›×™× ××“×™. × × ×œ×œ×—×•×¥ ×¢×œ '×”×ª×—×œ ××—×“×©' ×‘×¡×¨×’×œ ×”×¦×“ ×›×“×™ ×œ× ×§×•×ª ××ª ×”× ×ª×•× ×™× ×•×œ×”×ª×—×™×œ ×©×™×—×” ×—×“×©×”."
                    else:
                         error_detail += f" (×©×’×™××”: {e.status_code})" # Add status code for other 400s
                    full_response = f"××¦×˜×¢×¨, {error_detail}"
                    message_placeholder.error(full_response)
                except Exception as e:
                    logging.error(f"An unexpected error occurred during OpenAI API call: {e}", exc_info=True)
                    full_response = "××¦×˜×¢×¨, ××™×¨×¢×” ×©×’×™××” ×‘×œ×ª×™ ×¦×¤×•×™×” ×‘×¢×ª ×™×¦×™×¨×ª ×”×ª×’×•×‘×”. ×× × × ×¡×”/×™ ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨."
                    message_placeholder.error(full_response)

                # Update the content of the assistant's message in session state
                st.session_state.chat_messages[assistant_message_index]["content"] = full_response

            # Rerun the app to display the updated chat history
            st.rerun()

    else:
        st.warning("×©×™×¨×•×ª ×”×¦'××˜ ××™× ×• ×–××™×Ÿ. ×× × ×•×“×/×™ ×©××¤×ª×— ×”-API ×©×œ OpenAI ×”×•×’×“×¨ ×›×”×œ×›×”.")
